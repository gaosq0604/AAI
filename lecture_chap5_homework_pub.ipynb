{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 第5回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 課題. Tensorflowを用いて, MNISTを多層パーセプトロン(MLP)で学習せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- homework関数を完成させて提出してください\n",
    "    - 訓練データはtrain_X, train_y, テストデータはtest_Xで与えられます\n",
    "    - train_Xとtrain_yをtrain_X, train_yとvalid_X, valid_yに分けるなどしてモデルを学習させてください\n",
    "    - test_Xに対して予想ラベルpred_yを作り, homework関数の戻り値としてください\n",
    "- pred_yのtest_yに対する精度(F値)で評価します\n",
    "- 全体の実行時間がiLect上で60分を超えないようにしてください\n",
    "- homework関数の外には何も書かないでください (必要なものは全てhomework関数に入れてください)\n",
    "- 解答提出時には Answer Cell の内容のみを提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- CNNは使わないでください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**`tf` の以下のモジュールはこの回では使用できないように制限されています. 注意してください.**\n",
    "```python\n",
    "tf.app\n",
    "tf.compat\n",
    "tf.contrib\n",
    "tf.erros\n",
    "tf.gfile\n",
    "tf.graph_util\n",
    "tf.image\n",
    "tf.layers\n",
    "tf.logging\n",
    "tf.losses\n",
    "tf.metrics\n",
    "tf.python_io\n",
    "tf.resource_loader\n",
    "tf.saved_model\n",
    "tf.sdca\n",
    "tf.sets\n",
    "tf.summary\n",
    "tf.sysconfig\n",
    "tf.test\n",
    "tf.train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "次のセルのhomework関数を完成させて提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Answer Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    # WRITE ME!\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt\n",
    "    #%matplotlib inline\n",
    "    \n",
    "    #definition\n",
    "    \n",
    "    eps=0.1\n",
    "    #epoch_num=60\n",
    "    rng = np.random.RandomState(1234)\n",
    "    random_state = 42\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    t = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    w1 = tf.Variable(np.random.uniform(low=-0.08, high=0.08, size=(784, 100)).astype('float32'), name='w1')\n",
    "    b1 = tf.Variable(tf.zeros(100), name='b1')\n",
    "    \n",
    "    w2 = tf.Variable(np.random.uniform(low=-0.08, high=0.08, size=(100, 50)).astype('float32'), name='w2')\n",
    "    b2 = tf.Variable(tf.zeros(50), name='b2')\n",
    "    \n",
    "    w3 = tf.Variable(np.random.uniform(low=-0.08, high=0.08, size=(50, 10)).astype('float32'), name='w3')\n",
    "    b3 = tf.Variable(tf.zeros(10), name='b3')\n",
    "    \n",
    "    params = [w1, b1, w2, b2, w3, b3]\n",
    "    \n",
    "    #forward\n",
    "    \n",
    "    u1 = tf.matmul(x,w1)+b1\n",
    "    z1 = tf.nn.sigmoid(u1)\n",
    "    \n",
    "    u2 = tf.matmul(z1,w2)+b2\n",
    "    z2 = tf.nn.sigmoid(u2)\n",
    "    \n",
    "    u3 = tf.matmul(z2,w3)+b3\n",
    "    z3 = tf.nn.softmax(u3)\n",
    "    \n",
    "    y=z3\n",
    "    \n",
    "    # Step3. 誤差関数の定義\n",
    "    #cost = -tf.reduce_mean(tf.reduce_sum(t*tf.log(y)))\n",
    "    # tf.log(0)によるnanを防ぐ\n",
    "    cost = -tf.reduce_mean(tf.reduce_sum(t*tf.log(tf.clip_by_value(y, 1e-10, 1.0)),axis=1))\n",
    "    #cost = -np.log(y[0,np.nonzero(t)])\n",
    "    \n",
    "    #delta\n",
    "    gw1, gb1, gw2, gb2, gw3, gb3 = tf.gradients(cost, params)\n",
    "    updates = [\n",
    "        w1.assign_add(-eps*gw1), # 勾配降下法\n",
    "        b1.assign_add(-eps*gb1),\n",
    "        w2.assign_add(-eps*gw2), # 勾配降下法\n",
    "        b2.assign_add(-eps*gb2),\n",
    "        w3.assign_add(-eps*gw3), # 勾配降下法\n",
    "        b3.assign_add(-eps*gb3),\n",
    "    ]\n",
    "\n",
    "    train = tf.group(*updates)\n",
    "    \n",
    "    valid = tf.argmax(y, 1)\n",
    "    \n",
    "    start_time=time.time()\n",
    "    \n",
    "    #Online learning\n",
    "    \n",
    "    #cost_plt =[]\n",
    "    #sess = tf.Session()\n",
    "    #sess.run(tf.global_variables_initializer()) # 重みの初期化\n",
    "    #for epoch in range(epoch_num):\n",
    "    #    cost_arry = []\n",
    "    #    for x_in, y_in in zip(train_X, train_y):\n",
    "    #        x_in = x_in.reshape(1,len(x_in))\n",
    "    #        y_tmp = np.zeros(10).reshape(1, 10)\n",
    "    #        y_tmp[0,y_in] = 1.0\n",
    "    #        y_in=y_tmp\n",
    "    #        _cost, _ = sess.run([cost, train], feed_dict={x: x_in, t: y_in})\n",
    "    #        cost_arry.append(_cost)\n",
    "    #        \n",
    "    #    cost_plt.append(np.sum(cost_arry))\n",
    "    #    tttttt = time.time() - start\n",
    "    #    print (\"epoch\",epoch,\"time\",tttttt,\"cost\",cost_plt[len(cost_plt)-1])\n",
    "        #print(cost_plt)\n",
    "    #plt.plot(cost_plt)\n",
    "    \n",
    "    #batch learning\n",
    "    n_epochs = 300\n",
    "    batch_size = 100\n",
    "    n_batches = train_X.shape[0] // batch_size\n",
    "    \n",
    "    nb_classes = 10                                #train_y one-hot\n",
    "    targets = train_y.reshape(-1)\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    train_y = one_hot_targets\n",
    "    \n",
    "    # Step5. 学習\n",
    "    cost_plt =[]\n",
    "    with tf.Session() as sess:\n",
    "        print(\"start time\",start_time)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            train_X, train_y = shuffle(train_X, train_y, random_state=random_state)\n",
    "            cost_arry = []\n",
    "            for i in range(n_batches):\n",
    "                start = i * batch_size\n",
    "                end = start + batch_size\n",
    "                _cost, _ = sess.run([cost,train], feed_dict={x: train_X[start:end], t: train_y[start:end]})\n",
    "                cost_arry.append(_cost)\n",
    "                \n",
    "            cost_plt.append(np.sum(cost_arry))\n",
    "            tttttt = time.time()-start_time\n",
    "            #predict\n",
    "            #print (\"epoch\",epoch,\"time\",tttttt,\"cost\",cost_plt[len(cost_plt)-1])\n",
    "        pred_y = sess.run(valid, feed_dict={x: test_X})\n",
    "        print(\"time\",time.time()-start_time)\n",
    "        #plt.plot(cost_plt)\n",
    "    \n",
    "    # Step6. 予測\n",
    "    #pred_y = np.argmax(sess.run(y, feed_dict={x: test_X}),1)\n",
    "\n",
    "    #sess.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- 以下のvalidate_homework関数を用いてエラーが起きないか動作確認をして下さい。\n",
    "- 提出に際して、以下のscore_homework関数で60分で実行が終わることを確認して下さい。\n",
    "- 評価は以下のscore_homework関数で行われますが、random_stateの値は変更されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checker Cell (for student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "app",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-40a7a46cbe88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m del [\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: app"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "del [\n",
    "        tf.app,\n",
    "        tf.compat,\n",
    "        tf.contrib,\n",
    "        tf.errors,\n",
    "        tf.gfile,\n",
    "        tf.graph_util,\n",
    "        tf.image,\n",
    "        tf.layers,\n",
    "        tf.logging,\n",
    "        tf.losses,\n",
    "        tf.metrics,\n",
    "        tf.python_io,\n",
    "        tf.resource_loader,\n",
    "        tf.saved_model,\n",
    "        tf.sdca,\n",
    "        tf.sets,\n",
    "        tf.summary,\n",
    "        tf.sysconfig,\n",
    "        tf.test,\n",
    "        tf.train\n",
    "    ]\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                               mnist.target.astype('int32'), random_state=42)\n",
    "\n",
    "    mnist_X = mnist_X / 255.0\n",
    "\n",
    "    return train_test_split(mnist_X, mnist_y,\n",
    "                test_size=0.2,\n",
    "                random_state=42)\n",
    "\n",
    "def validate_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "\n",
    "    # validate for small dataset\n",
    "    train_X_mini = train_X[:1000]\n",
    "    train_y_mini = train_y[:1000]\n",
    "    test_X_mini = test_X[:1000]\n",
    "    test_y_mini = test_y[:1000]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "    print(f1_score(test_y_mini, pred_y, average='macro'))\n",
    "\n",
    "def score_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    pred_y = homework(train_X, train_y, test_X)\n",
    "    print(f1_score(test_y, pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 1494687248.9957433\n",
      "time 6.668147802352905\n",
      "0.818011287119\n"
     ]
    }
   ],
   "source": [
    "validate_homework()\n",
    "#score_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 1494686514.3962884\n",
      "epoch 0 time 1.3128020763397217 cost 1282.96\n",
      "epoch 1 time 2.580892324447632 cost 1053.36\n",
      "epoch 2 time 3.8719305992126465 cost 551.524\n",
      "epoch 3 time 5.143477916717529 cost 375.435\n",
      "epoch 4 time 6.424375057220459 cost 284.147\n",
      "epoch 5 time 7.7073814868927 cost 232.635\n",
      "epoch 6 time 8.98240065574646 cost 205.503\n",
      "epoch 7 time 10.257305383682251 cost 188.421\n",
      "epoch 8 time 11.534261226654053 cost 175.616\n",
      "epoch 9 time 12.812152862548828 cost 164.942\n",
      "epoch 10 time 14.086116790771484 cost 155.647\n",
      "epoch 11 time 15.354918718338013 cost 147.27\n",
      "epoch 12 time 16.63156533241272 cost 139.44\n",
      "epoch 13 time 17.91119122505188 cost 132.305\n",
      "epoch 14 time 19.18448543548584 cost 125.528\n",
      "epoch 15 time 20.455199241638184 cost 119.361\n",
      "epoch 16 time 21.7320499420166 cost 113.614\n",
      "epoch 17 time 23.003784656524658 cost 108.567\n",
      "epoch 18 time 24.275479555130005 cost 103.482\n",
      "epoch 19 time 25.55088472366333 cost 99.1859\n",
      "epoch 20 time 26.82466769218445 cost 94.9684\n",
      "epoch 21 time 28.105546951293945 cost 91.2183\n",
      "epoch 22 time 29.378971815109253 cost 87.8455\n",
      "epoch 23 time 30.65095067024231 cost 84.6389\n",
      "epoch 24 time 31.926470279693604 cost 81.5679\n",
      "epoch 25 time 33.1963369846344 cost 78.6675\n",
      "epoch 26 time 34.47609257698059 cost 76.038\n",
      "epoch 27 time 35.7506468296051 cost 73.6377\n",
      "epoch 28 time 37.023239850997925 cost 71.2077\n",
      "epoch 29 time 38.29840707778931 cost 68.9528\n",
      "epoch 30 time 39.5739061832428 cost 66.9301\n",
      "epoch 31 time 40.86071181297302 cost 64.9706\n",
      "epoch 32 time 42.13272213935852 cost 62.9796\n",
      "epoch 33 time 43.40493822097778 cost 61.2057\n",
      "epoch 34 time 44.6805214881897 cost 59.5606\n",
      "epoch 35 time 45.94935894012451 cost 57.9187\n",
      "epoch 36 time 47.23177146911621 cost 56.4104\n",
      "epoch 37 time 48.509467363357544 cost 54.8907\n",
      "epoch 38 time 49.79113721847534 cost 53.4112\n",
      "epoch 39 time 51.06198978424072 cost 52.1403\n",
      "epoch 40 time 52.33325958251953 cost 50.7169\n",
      "epoch 41 time 53.60846924781799 cost 49.5713\n",
      "epoch 42 time 54.88289785385132 cost 48.3268\n",
      "epoch 43 time 56.15400409698486 cost 47.0656\n",
      "epoch 44 time 57.42137336730957 cost 45.9696\n",
      "epoch 45 time 58.70396852493286 cost 44.948\n",
      "epoch 46 time 59.9782612323761 cost 43.8997\n",
      "epoch 47 time 61.25286149978638 cost 42.9293\n",
      "epoch 48 time 62.5286021232605 cost 41.8358\n",
      "epoch 49 time 63.80395007133484 cost 40.7979\n",
      "epoch 50 time 65.07672715187073 cost 40.0126\n",
      "epoch 51 time 66.35021138191223 cost 39.1054\n",
      "epoch 52 time 67.62584805488586 cost 38.1707\n",
      "epoch 53 time 68.90682697296143 cost 37.3807\n",
      "epoch 54 time 70.18422031402588 cost 36.5045\n",
      "epoch 55 time 71.45898056030273 cost 35.7282\n",
      "epoch 56 time 72.73798179626465 cost 34.9352\n",
      "epoch 57 time 74.00705409049988 cost 34.2126\n",
      "epoch 58 time 75.28081607818604 cost 33.3546\n",
      "epoch 59 time 76.55069780349731 cost 32.7957\n",
      "epoch 60 time 77.82518815994263 cost 32.0801\n",
      "epoch 61 time 79.10023093223572 cost 31.32\n",
      "epoch 62 time 80.37933993339539 cost 30.6571\n",
      "epoch 63 time 81.6581289768219 cost 30.1073\n",
      "epoch 64 time 82.93306493759155 cost 29.3242\n",
      "epoch 65 time 84.21369862556458 cost 28.7229\n",
      "epoch 66 time 85.48842716217041 cost 28.1124\n",
      "epoch 67 time 86.75964856147766 cost 27.6025\n",
      "epoch 68 time 88.03516340255737 cost 27.0682\n",
      "epoch 69 time 89.30973744392395 cost 26.3812\n",
      "epoch 70 time 90.58515691757202 cost 25.8338\n",
      "epoch 71 time 91.85331559181213 cost 25.312\n",
      "epoch 72 time 93.13135552406311 cost 24.7985\n",
      "epoch 73 time 94.41758942604065 cost 24.2998\n",
      "epoch 74 time 95.69406700134277 cost 23.81\n",
      "epoch 75 time 96.98146605491638 cost 23.279\n",
      "epoch 76 time 98.260338306427 cost 22.7939\n",
      "epoch 77 time 99.53198337554932 cost 22.4189\n",
      "epoch 78 time 100.80277442932129 cost 21.9825\n",
      "epoch 79 time 102.08187246322632 cost 21.4449\n",
      "epoch 80 time 103.35570645332336 cost 21.0913\n",
      "epoch 81 time 104.62533473968506 cost 20.6667\n",
      "epoch 82 time 105.9000654220581 cost 20.2106\n",
      "epoch 83 time 107.17225623130798 cost 19.8276\n",
      "epoch 84 time 108.45452833175659 cost 19.3724\n",
      "epoch 85 time 109.73702836036682 cost 18.9286\n",
      "epoch 86 time 111.00823545455933 cost 18.6086\n",
      "epoch 87 time 112.29541373252869 cost 18.2319\n",
      "epoch 88 time 113.56621551513672 cost 17.8059\n",
      "epoch 89 time 114.83364701271057 cost 17.487\n",
      "epoch 90 time 116.11234211921692 cost 17.1382\n",
      "epoch 91 time 117.38875555992126 cost 16.7892\n",
      "epoch 92 time 118.66598987579346 cost 16.4677\n",
      "epoch 93 time 119.93597936630249 cost 16.1163\n",
      "epoch 94 time 121.2150444984436 cost 15.8236\n",
      "epoch 95 time 122.49232006072998 cost 15.4514\n",
      "epoch 96 time 123.77199840545654 cost 15.1611\n",
      "epoch 97 time 125.04966998100281 cost 14.8549\n",
      "epoch 98 time 126.32103252410889 cost 14.5717\n",
      "epoch 99 time 127.59656381607056 cost 14.2821\n",
      "epoch 100 time 128.8775930404663 cost 14.0066\n",
      "epoch 101 time 130.1483747959137 cost 13.6937\n",
      "epoch 102 time 131.41948103904724 cost 13.4249\n",
      "epoch 103 time 132.69532418251038 cost 13.2245\n",
      "epoch 104 time 133.97599148750305 cost 12.951\n",
      "epoch 105 time 135.2561638355255 cost 12.6301\n",
      "epoch 106 time 136.53334832191467 cost 12.4323\n",
      "epoch 107 time 137.8116581439972 cost 12.1443\n",
      "epoch 108 time 139.09583282470703 cost 11.8998\n",
      "epoch 109 time 140.38206124305725 cost 11.6734\n",
      "epoch 110 time 141.66965627670288 cost 11.4344\n",
      "epoch 111 time 142.94802451133728 cost 11.2149\n",
      "epoch 112 time 144.23493027687073 cost 10.9894\n",
      "epoch 113 time 145.5128149986267 cost 10.8049\n",
      "epoch 114 time 146.80547213554382 cost 10.5432\n",
      "epoch 115 time 148.0910439491272 cost 10.3963\n",
      "epoch 116 time 149.38146829605103 cost 10.192\n",
      "epoch 117 time 150.6657681465149 cost 9.99035\n",
      "epoch 118 time 151.94183778762817 cost 9.82067\n",
      "epoch 119 time 153.22921752929688 cost 9.6256\n",
      "epoch 120 time 154.52374577522278 cost 9.38526\n",
      "epoch 121 time 155.80412602424622 cost 9.26987\n",
      "epoch 122 time 157.0843734741211 cost 9.05943\n",
      "epoch 123 time 158.36928915977478 cost 8.88207\n",
      "epoch 124 time 159.650532245636 cost 8.7811\n",
      "epoch 125 time 160.9246301651001 cost 8.58821\n",
      "epoch 126 time 162.2063524723053 cost 8.46887\n",
      "epoch 127 time 163.50397157669067 cost 8.272\n",
      "epoch 128 time 164.79756140708923 cost 8.12606\n",
      "epoch 129 time 166.0808608531952 cost 7.96783\n",
      "epoch 130 time 167.3627371788025 cost 7.84567\n",
      "epoch 131 time 168.6549506187439 cost 7.68995\n",
      "epoch 132 time 169.94932293891907 cost 7.55663\n",
      "epoch 133 time 171.23651432991028 cost 7.39915\n",
      "epoch 134 time 172.5276186466217 cost 7.28243\n",
      "epoch 135 time 173.81933403015137 cost 7.13674\n",
      "epoch 136 time 175.11490678787231 cost 7.03162\n",
      "epoch 137 time 176.4048295021057 cost 6.89937\n",
      "epoch 138 time 177.6864857673645 cost 6.77817\n",
      "epoch 139 time 178.97937655448914 cost 6.6635\n",
      "epoch 140 time 180.27673649787903 cost 6.57793\n",
      "epoch 141 time 181.56954407691956 cost 6.44711\n",
      "epoch 142 time 182.85597443580627 cost 6.33567\n",
      "epoch 143 time 184.1620397567749 cost 6.2219\n",
      "epoch 144 time 185.45456290245056 cost 6.14137\n",
      "epoch 145 time 186.73054957389832 cost 6.00874\n",
      "epoch 146 time 188.01622128486633 cost 5.94439\n",
      "epoch 147 time 189.29580092430115 cost 5.84226\n",
      "epoch 148 time 190.58336734771729 cost 5.7259\n",
      "epoch 149 time 191.86305165290833 cost 5.64991\n",
      "epoch 150 time 193.14969754219055 cost 5.57181\n",
      "epoch 151 time 194.4388885498047 cost 5.47823\n",
      "epoch 152 time 195.72212719917297 cost 5.36101\n",
      "epoch 153 time 197.00148797035217 cost 5.31665\n",
      "epoch 154 time 198.28109121322632 cost 5.21813\n",
      "epoch 155 time 199.55219864845276 cost 5.13123\n",
      "epoch 156 time 200.8232080936432 cost 5.03752\n",
      "epoch 157 time 202.0991861820221 cost 4.98337\n",
      "epoch 158 time 203.37906289100647 cost 4.90834\n",
      "epoch 159 time 204.65403270721436 cost 4.83682\n",
      "epoch 160 time 205.93121242523193 cost 4.75724\n",
      "epoch 161 time 207.2030086517334 cost 4.68301\n",
      "epoch 162 time 208.47594547271729 cost 4.63836\n",
      "epoch 163 time 209.7509469985962 cost 4.56194\n",
      "epoch 164 time 211.0215368270874 cost 4.4851\n",
      "epoch 165 time 212.2988965511322 cost 4.41657\n",
      "epoch 166 time 213.57372665405273 cost 4.36031\n",
      "epoch 167 time 214.8487207889557 cost 4.29348\n",
      "epoch 168 time 216.1324486732483 cost 4.23885\n",
      "epoch 169 time 217.4034607410431 cost 4.17459\n",
      "epoch 170 time 218.67826175689697 cost 4.11326\n",
      "epoch 171 time 219.95123863220215 cost 4.0539\n",
      "epoch 172 time 221.23124861717224 cost 4.01002\n",
      "epoch 173 time 222.51202869415283 cost 3.95547\n",
      "epoch 174 time 223.78407549858093 cost 3.90001\n",
      "epoch 175 time 225.05958342552185 cost 3.84236\n",
      "epoch 176 time 226.33574104309082 cost 3.79154\n",
      "epoch 177 time 227.6095335483551 cost 3.74814\n",
      "epoch 178 time 228.88011860847473 cost 3.69866\n",
      "epoch 179 time 230.15356826782227 cost 3.6545\n",
      "epoch 180 time 231.42430758476257 cost 3.60014\n",
      "epoch 181 time 232.70961236953735 cost 3.55303\n",
      "epoch 182 time 233.98596334457397 cost 3.5054\n",
      "epoch 183 time 235.26304697990417 cost 3.45716\n",
      "epoch 184 time 236.53287601470947 cost 3.42464\n",
      "epoch 185 time 237.81593489646912 cost 3.3803\n",
      "epoch 186 time 239.09190249443054 cost 3.34012\n",
      "epoch 187 time 240.37260222434998 cost 3.30129\n",
      "epoch 188 time 241.65039706230164 cost 3.253\n",
      "epoch 189 time 242.9288547039032 cost 3.21172\n",
      "epoch 190 time 244.20510482788086 cost 3.18087\n",
      "epoch 191 time 245.4879093170166 cost 3.13793\n",
      "epoch 192 time 246.7628846168518 cost 3.09192\n",
      "epoch 193 time 248.04403710365295 cost 3.0662\n",
      "epoch 194 time 249.33382749557495 cost 3.02337\n",
      "epoch 195 time 250.63099837303162 cost 2.99578\n",
      "epoch 196 time 251.90932178497314 cost 2.96656\n",
      "epoch 197 time 253.1969769001007 cost 2.92885\n",
      "epoch 198 time 254.48927211761475 cost 2.89232\n",
      "epoch 199 time 255.78071570396423 cost 2.86624\n",
      "epoch 200 time 257.07866501808167 cost 2.83277\n",
      "epoch 201 time 258.3726170063019 cost 2.79656\n",
      "epoch 202 time 259.66789841651917 cost 2.77066\n",
      "epoch 203 time 260.9628863334656 cost 2.7351\n",
      "epoch 204 time 262.2596137523651 cost 2.70206\n",
      "epoch 205 time 263.5493905544281 cost 2.67149\n",
      "epoch 206 time 264.83757424354553 cost 2.64761\n",
      "epoch 207 time 266.12891578674316 cost 2.62104\n",
      "epoch 208 time 267.4192523956299 cost 2.59025\n",
      "epoch 209 time 268.7060856819153 cost 2.56549\n",
      "epoch 210 time 269.9845826625824 cost 2.53679\n",
      "epoch 211 time 271.2686722278595 cost 2.50716\n",
      "epoch 212 time 272.5736315250397 cost 2.48189\n",
      "epoch 213 time 273.8654475212097 cost 2.45771\n",
      "epoch 214 time 275.1730842590332 cost 2.43333\n",
      "epoch 215 time 276.46330189704895 cost 2.40728\n",
      "epoch 216 time 277.748628616333 cost 2.38217\n",
      "epoch 217 time 279.0444812774658 cost 2.35712\n",
      "epoch 218 time 280.33295488357544 cost 2.33021\n",
      "epoch 219 time 281.6262364387512 cost 2.31019\n",
      "epoch 220 time 282.9193193912506 cost 2.29247\n",
      "epoch 221 time 284.2184693813324 cost 2.26171\n",
      "epoch 222 time 285.51887488365173 cost 2.23587\n",
      "epoch 223 time 286.8017666339874 cost 2.21878\n",
      "epoch 224 time 288.0895125865936 cost 2.20184\n",
      "epoch 225 time 289.37826442718506 cost 2.17381\n",
      "epoch 226 time 290.6810460090637 cost 2.15627\n",
      "epoch 227 time 291.9786548614502 cost 2.13623\n",
      "epoch 228 time 293.2767198085785 cost 2.11566\n",
      "epoch 229 time 294.56664657592773 cost 2.09641\n",
      "epoch 230 time 295.8595974445343 cost 2.07923\n",
      "epoch 231 time 297.1500427722931 cost 2.0595\n",
      "epoch 232 time 298.4519793987274 cost 2.0388\n",
      "epoch 233 time 299.75365591049194 cost 2.01914\n",
      "epoch 234 time 301.0356659889221 cost 1.99655\n",
      "epoch 235 time 302.3283770084381 cost 1.98076\n",
      "epoch 236 time 303.6190011501312 cost 1.96273\n",
      "epoch 237 time 304.9127461910248 cost 1.94302\n",
      "epoch 238 time 306.20495438575745 cost 1.93087\n",
      "epoch 239 time 307.49199318885803 cost 1.90577\n",
      "epoch 240 time 308.7735996246338 cost 1.8936\n",
      "epoch 241 time 310.0599012374878 cost 1.87517\n",
      "epoch 242 time 311.3522653579712 cost 1.86409\n",
      "epoch 243 time 312.64510560035706 cost 1.84485\n",
      "epoch 244 time 313.9356791973114 cost 1.83015\n",
      "epoch 245 time 315.22889018058777 cost 1.80892\n",
      "epoch 246 time 316.52678394317627 cost 1.79648\n",
      "epoch 247 time 317.8200521469116 cost 1.77541\n",
      "epoch 248 time 319.1184527873993 cost 1.76179\n",
      "epoch 249 time 320.42055320739746 cost 1.75012\n",
      "epoch 250 time 321.707319021225 cost 1.73534\n",
      "epoch 251 time 322.9998342990875 cost 1.72132\n",
      "epoch 252 time 324.29132318496704 cost 1.70686\n",
      "epoch 253 time 325.57497477531433 cost 1.69373\n",
      "epoch 254 time 326.8657419681549 cost 1.67686\n",
      "epoch 255 time 328.1617136001587 cost 1.66511\n",
      "epoch 256 time 329.46109414100647 cost 1.64869\n",
      "epoch 257 time 330.75159978866577 cost 1.63951\n",
      "epoch 258 time 332.0492146015167 cost 1.62944\n",
      "epoch 259 time 333.32156109809875 cost 1.61394\n",
      "epoch 260 time 334.60876393318176 cost 1.59731\n",
      "epoch 261 time 335.9034378528595 cost 1.58713\n",
      "epoch 262 time 337.19675278663635 cost 1.57413\n",
      "epoch 263 time 338.4814250469208 cost 1.56611\n",
      "epoch 264 time 339.78636717796326 cost 1.54782\n",
      "epoch 265 time 341.07271671295166 cost 1.53484\n",
      "epoch 266 time 342.36317920684814 cost 1.52633\n",
      "epoch 267 time 343.64901876449585 cost 1.5132\n",
      "epoch 268 time 344.9311099052429 cost 1.50382\n",
      "epoch 269 time 346.22260308265686 cost 1.49433\n",
      "epoch 270 time 347.50668954849243 cost 1.4817\n",
      "epoch 271 time 348.7966811656952 cost 1.47146\n",
      "epoch 272 time 350.0798749923706 cost 1.45817\n",
      "epoch 273 time 351.3648316860199 cost 1.44524\n",
      "epoch 274 time 352.66005396842957 cost 1.43421\n",
      "epoch 275 time 353.9548120498657 cost 1.42622\n",
      "epoch 276 time 355.2655780315399 cost 1.41538\n",
      "epoch 277 time 356.5596466064453 cost 1.40441\n",
      "epoch 278 time 357.8534963130951 cost 1.39524\n",
      "epoch 279 time 359.1430473327637 cost 1.38423\n",
      "epoch 280 time 360.43437123298645 cost 1.37642\n",
      "epoch 281 time 361.7183904647827 cost 1.36508\n",
      "epoch 282 time 363.0044095516205 cost 1.3583\n",
      "epoch 283 time 364.2952754497528 cost 1.3467\n",
      "epoch 284 time 365.58623003959656 cost 1.33646\n",
      "epoch 285 time 366.8575048446655 cost 1.33041\n",
      "epoch 286 time 368.13693928718567 cost 1.31965\n",
      "epoch 287 time 369.41682958602905 cost 1.30916\n",
      "epoch 288 time 370.70916175842285 cost 1.30266\n",
      "epoch 289 time 372.0015606880188 cost 1.29058\n",
      "epoch 290 time 373.29641604423523 cost 1.2827\n",
      "epoch 291 time 374.60496735572815 cost 1.27609\n",
      "epoch 292 time 375.8936104774475 cost 1.26625\n",
      "epoch 293 time 377.185165643692 cost 1.25837\n",
      "epoch 294 time 378.4825339317322 cost 1.24924\n",
      "epoch 295 time 379.7656903266907 cost 1.24024\n",
      "epoch 296 time 381.05362033843994 cost 1.23249\n",
      "epoch 297 time 382.3435010910034 cost 1.22586\n",
      "epoch 298 time 383.64012122154236 cost 1.21786\n",
      "epoch 299 time 384.92357420921326 cost 1.20975\n",
      "385.02345418930054\n",
      "0.978296884281\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b7ca5a978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
