{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. Tensorflowを用いて, MNISTを畳み込みニューラルネットワーク(CNN)で学習せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- homework関数を完成させて提出してください\n",
    "    - 訓練データはtrain_X, train_y, テストデータはtest_Xで与えられます\n",
    "    - train_Xとtrain_yをtrain_X, train_yとvalid_X, valid_yに分けるなどしてモデルを学習させてください\n",
    "    - test_Xに対して予想ラベルpred_yを作り, homework関数の戻り値としてください\\\n",
    "- pred_yのtest_yに対する精度(F値)で評価します\n",
    "- 全体の実行時間がiLect上で60分を超えないようにしてください\n",
    "- homework関数の外には何も書かないでください (必要なものは全てhomework関数に入れてください)\n",
    "- 解答提出時には Answer Cell の内容のみを提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf` の以下のモジュールはこの回では使用できないように制限されています. 注意してください.**\n",
    "```python\n",
    "tf.app\n",
    "tf.compat\n",
    "tf.contrib\n",
    "tf.erros\n",
    "tf.gfile\n",
    "tf.graph_util\n",
    "tf.image\n",
    "tf.layers\n",
    "tf.logging\n",
    "tf.losses\n",
    "tf.metrics\n",
    "tf.python_io\n",
    "tf.resource_loader\n",
    "tf.saved_model\n",
    "tf.sdca\n",
    "tf.sets\n",
    "tf.summary\n",
    "tf.sysconfig\n",
    "tf.test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルのhomework関数を完成させて提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt\n",
    "    #%matplotlib inline\n",
    "    rng = np.random.RandomState(1234)\n",
    "    random_state = 42\n",
    "    #Convolution layers [batchsize,picture_length,picture_width,color_channels]\n",
    "    class Conv:\n",
    "        def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
    "            # Xavier Initialization\n",
    "            fan_in = np.prod(filter_shape[:3])\n",
    "            fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "            self.W = tf.Variable(rng.uniform(\n",
    "                            low=-np.sqrt(6/(fan_in + fan_out)),\n",
    "                            high=np.sqrt(6/(fan_in + fan_out)),\n",
    "                            size=filter_shape\n",
    "                        ).astype('float32'), name='W')\n",
    "            self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
    "            self.function = function\n",
    "            self.strides = strides\n",
    "            self.padding = padding\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding)+self.b\n",
    "            return self.function(u)\n",
    "    class Conv_same:\n",
    "        def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='SAME'):\n",
    "            # Xavier Initialization\n",
    "            fan_in = np.prod(filter_shape[:3])\n",
    "            fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "            self.W = tf.Variable(rng.uniform(\n",
    "                            low=-np.sqrt(6/(fan_in + fan_out)),\n",
    "                            high=np.sqrt(6/(fan_in + fan_out)),\n",
    "                            size=filter_shape\n",
    "                        ).astype('float32'), name='W')\n",
    "            self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
    "            self.function = function\n",
    "            self.strides = strides\n",
    "            self.padding = padding\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding)+self.b\n",
    "            return self.function(u)\n",
    "    #Pooling layers [batchsize,picture_length,picture_width,color_channels]\n",
    "    class Pooling:\n",
    "        def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME'):\n",
    "            self.ksize = ksize\n",
    "            self.strides = strides\n",
    "            self.padding = padding\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
    "    #Flatten layer    \n",
    "    class Flatten:\n",
    "        def f_prop(self, x):\n",
    "            return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
    "    #Full-link layers\n",
    "    class Dense:\n",
    "        def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "            # Xavier Initialization\n",
    "            self.W = tf.Variable(rng.uniform(\n",
    "                            low=-np.sqrt(6/(in_dim + out_dim)),\n",
    "                            high=np.sqrt(6/(in_dim + out_dim)),\n",
    "                            size=(in_dim, out_dim)\n",
    "                        ).astype('float32'), name='W')\n",
    "            self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "            self.function = function\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            return self.function(tf.matmul(x, self.W) + self.b)\n",
    "    \n",
    "    layers = [                            # (縦の次元数)x(横の次元数)x(チャネル数)\n",
    "        Conv_same((5, 5, 1, 20), tf.nn.relu),  # 28x28x 1 -> 28x28x20\n",
    "        Pooling((1, 2, 2, 1)),            # 28x28x20 -> 14x14x20\n",
    "        Conv((5, 5, 20, 50), tf.nn.relu), # 14x14x20 ->  10x 10x50\n",
    "        Pooling((1, 2, 2, 1)),            #  10x 10x50 ->  5x 5x50\n",
    "        Flatten(),\n",
    "        Dense(5*5*50, 10, tf.nn.softmax)\n",
    "    ]\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "    t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    def f_props(layers, x):\n",
    "        for layer in layers:\n",
    "            x = layer.f_prop(x)\n",
    "        return x\n",
    "\n",
    "    y = f_props(layers, x)\n",
    "\n",
    "    cost = -tf.reduce_mean(tf.reduce_sum(t * tf.log(tf.clip_by_value(y, 1e-10, 1.0)), axis=1)) # tf.log(0)によるnanを防ぐ\n",
    "    train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "    valid = tf.argmax(y, 1)\n",
    "    \n",
    "    n_epochs = 200\n",
    "    batch_size = 100\n",
    "    n_batches = train_X.shape[0]//batch_size\n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    cost_plt =[]\n",
    "    start_time=time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_X, train_y = shuffle(train_X, train_y, random_state=random_state)\n",
    "        cost_arry = []\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            _cost, _ = sess.run([cost,train], feed_dict={x: train_X[start:end], t: train_y[start:end]})\n",
    "            cost_arry.append(_cost)\n",
    "        cost_plt.append(np.sum(cost_arry))\n",
    "        tttttt = time.time()-start_time\n",
    "        print (\"epoch\",epoch,\"time\",tttttt,\"cost\",cost_plt[len(cost_plt)-1])\n",
    "\n",
    "        pred_y = sess.run(valid, feed_dict={x: test_X})\n",
    "        \n",
    "    sess.close()\n",
    "    plt.plot(np.log(cost_plt))\n",
    "    \n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以下のvalidate_homework関数を用いてエラーが起きないか動作確認をして下さい。\n",
    "- 提出に際して、以下のscore_homework関数で60分で実行が終わることを確認して下さい。\n",
    "- 評価は以下のscore_homework関数で行われますが、random_stateの値は変更されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checker Cell (for student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "app",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c8f29b234267>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m del [\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: app"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "del [\n",
    "        tf.app,\n",
    "        tf.compat,\n",
    "        tf.contrib,\n",
    "        tf.errors,\n",
    "        tf.gfile,\n",
    "        tf.graph_util,\n",
    "        tf.image,\n",
    "        tf.layers,\n",
    "        tf.logging,\n",
    "        tf.losses,\n",
    "        tf.metrics,\n",
    "        tf.python_io,\n",
    "        tf.resource_loader,\n",
    "        tf.saved_model,\n",
    "        tf.sdca,\n",
    "        tf.sets,\n",
    "        tf.summary,\n",
    "        tf.sysconfig,\n",
    "        tf.test\n",
    "]\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "    mnist_X = np.r_[mnist.train.images, mnist.test.images]\n",
    "    mnist_y = np.r_[mnist.train.labels, mnist.test.labels]\n",
    "    return train_test_split(mnist_X, mnist_y, test_size=0.2, random_state=42)\n",
    "\n",
    "def validate_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    train_X = train_X.reshape((train_X.shape[0], 28, 28, 1))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 28, 28, 1))\n",
    "\n",
    "    # validate for small dataset\n",
    "    train_X_mini = train_X[:5000]\n",
    "    train_y_mini = train_y[:5000]\n",
    "    test_X_mini = test_X[:1000]\n",
    "    test_y_mini = test_y[:1000]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "    print(f1_score(np.argmax(test_y_mini, 1), pred_y, average='macro'))\n",
    "\n",
    "def score_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    train_X = train_X.reshape((train_X.shape[0], 28, 28, 1))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 28, 28, 1))\n",
    "    \n",
    "    pred_y = homework(train_X, train_y, test_X)\n",
    "    print(f1_score(np.argmax(test_y, 1), pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate_homework()\n",
    "#score_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "epoch 0 time 3.3471519947052 cost 476.076\n",
      "epoch 1 time 6.79206395149231 cost 142.758\n",
      "epoch 2 time 10.220931768417358 cost 104.104\n",
      "epoch 3 time 13.657320499420166 cost 83.3537\n",
      "epoch 4 time 17.07565951347351 cost 70.0701\n",
      "epoch 5 time 20.501519203186035 cost 60.6473\n",
      "epoch 6 time 23.92888355255127 cost 54.0841\n",
      "epoch 7 time 27.35875368118286 cost 49.056\n",
      "epoch 8 time 30.791131734848022 cost 45.5713\n",
      "epoch 9 time 34.23905110359192 cost 42.0872\n",
      "epoch 10 time 37.707026720047 cost 39.3179\n",
      "epoch 11 time 41.14742565155029 cost 37.0917\n",
      "epoch 12 time 44.59534573554993 cost 35.2514\n",
      "epoch 13 time 48.08588242530823 cost 33.2155\n",
      "epoch 14 time 51.50267481803894 cost 32.0766\n",
      "epoch 15 time 54.92503547668457 cost 30.7365\n",
      "epoch 16 time 58.14843010902405 cost 29.3709\n",
      "epoch 17 time 61.554248094558716 cost 28.5443\n",
      "epoch 18 time 65.05832123756409 cost 27.5777\n",
      "epoch 19 time 68.39393472671509 cost 26.7318\n",
      "epoch 20 time 71.8904881477356 cost 25.7402\n",
      "epoch 21 time 75.45472931861877 cost 24.9779\n",
      "epoch 22 time 78.9452657699585 cost 24.2011\n",
      "epoch 23 time 82.43279361724854 cost 23.6439\n",
      "epoch 24 time 85.90227341651917 cost 22.8197\n",
      "epoch 25 time 89.38077640533447 cost 22.1313\n",
      "epoch 26 time 92.84022784233093 cost 21.721\n",
      "epoch 27 time 96.33678078651428 cost 21.0541\n",
      "epoch 28 time 99.82781839370728 cost 20.6479\n",
      "epoch 29 time 103.31033301353455 cost 20.237\n",
      "epoch 30 time 106.85050511360168 cost 19.5007\n",
      "epoch 31 time 110.3340232372284 cost 19.1323\n",
      "epoch 32 time 113.7944769859314 cost 19.1188\n",
      "epoch 33 time 117.26947069168091 cost 18.4328\n",
      "epoch 34 time 120.72791934013367 cost 17.9519\n",
      "epoch 35 time 124.21494626998901 cost 17.5758\n",
      "epoch 36 time 127.71450734138489 cost 17.3733\n",
      "epoch 37 time 131.20153403282166 cost 17.0367\n",
      "epoch 38 time 134.6589801311493 cost 16.6403\n",
      "epoch 39 time 138.14901542663574 cost 16.3695\n",
      "epoch 40 time 141.5553433895111 cost 15.8551\n",
      "epoch 41 time 145.05340051651 cost 15.5116\n",
      "epoch 42 time 148.46572256088257 cost 15.4154\n",
      "epoch 43 time 151.37216424942017 cost 15.1273\n",
      "epoch 44 time 154.60877466201782 cost 14.7743\n",
      "epoch 45 time 158.11632084846497 cost 14.6333\n",
      "epoch 46 time 161.83614373207092 cost 14.3133\n",
      "epoch 47 time 165.25832724571228 cost 14.1042\n",
      "epoch 48 time 168.75879669189453 cost 13.8676\n",
      "epoch 49 time 172.00233435630798 cost 13.7343\n",
      "epoch 50 time 175.9664430618286 cost 13.2935\n",
      "epoch 51 time 179.34407687187195 cost 12.9669\n",
      "epoch 52 time 182.55072712898254 cost 12.7387\n",
      "epoch 53 time 185.91105961799622 cost 12.611\n",
      "epoch 54 time 189.81157779693604 cost 12.682\n",
      "epoch 55 time 193.8355677127838 cost 12.1918\n",
      "epoch 56 time 198.11081457138062 cost 12.2357\n",
      "epoch 57 time 201.81677651405334 cost 11.7095\n",
      "epoch 58 time 206.10680103302002 cost 11.7749\n",
      "epoch 59 time 209.77966618537903 cost 11.4412\n",
      "epoch 60 time 213.83729457855225 cost 11.299\n",
      "epoch 61 time 217.85340785980225 cost 11.2585\n",
      "epoch 62 time 221.71137142181396 cost 10.9726\n",
      "epoch 63 time 225.73114800453186 cost 10.6342\n",
      "epoch 64 time 229.70516395568848 cost 10.57\n",
      "epoch 65 time 233.59846901893616 cost 10.5397\n",
      "epoch 66 time 237.32955980300903 cost 10.1457\n",
      "epoch 67 time 241.22885847091675 cost 10.0651\n",
      "epoch 68 time 245.09666752815247 cost 10.0085\n",
      "epoch 69 time 249.4095721244812 cost 9.88687\n",
      "epoch 70 time 253.27652716636658 cost 9.66516\n",
      "epoch 71 time 257.24032855033875 cost 9.43774\n",
      "epoch 72 time 260.88135838508606 cost 9.53433\n",
      "epoch 73 time 264.7297570705414 cost 9.31039\n",
      "epoch 74 time 268.53070521354675 cost 9.14603\n",
      "epoch 75 time 272.476930141449 cost 9.10653\n",
      "epoch 76 time 276.1818268299103 cost 8.89878\n",
      "epoch 77 time 279.5319983959198 cost 8.77052\n",
      "epoch 78 time 283.3743190765381 cost 8.5358\n",
      "epoch 79 time 287.00955629348755 cost 8.47339\n",
      "epoch 80 time 291.1143627166748 cost 8.36248\n",
      "epoch 81 time 294.59257531166077 cost 8.20772\n",
      "epoch 82 time 298.4579815864563 cost 8.08801\n",
      "epoch 83 time 302.33961606025696 cost 8.12622\n",
      "epoch 84 time 306.19297218322754 cost 7.83202\n",
      "epoch 85 time 310.23412561416626 cost 7.74829\n",
      "epoch 86 time 313.72858023643494 cost 7.63031\n",
      "epoch 87 time 317.75154852867126 cost 7.44555\n",
      "epoch 88 time 321.17091512680054 cost 7.38239\n",
      "epoch 89 time 324.47319173812866 cost 7.41908\n",
      "epoch 90 time 328.32975816726685 cost 7.13837\n",
      "epoch 91 time 331.66296219825745 cost 7.12056\n",
      "epoch 92 time 335.02190589904785 cost 6.94301\n",
      "epoch 93 time 338.08062386512756 cost 6.92805\n",
      "epoch 94 time 341.6858580112457 cost 6.79305\n",
      "epoch 95 time 345.05746483802795 cost 6.68723\n",
      "epoch 96 time 348.37044382095337 cost 6.652\n",
      "epoch 97 time 351.7089993953705 cost 6.48062\n",
      "epoch 98 time 354.8002669811249 cost 6.33638\n",
      "epoch 99 time 358.02272939682007 cost 6.30913\n",
      "epoch 100 time 361.17420959472656 cost 6.34899\n",
      "epoch 101 time 364.25713658332825 cost 6.2913\n",
      "epoch 102 time 367.7129771709442 cost 6.03174\n",
      "epoch 103 time 371.24225783348083 cost 5.91799\n",
      "epoch 104 time 374.6461811065674 cost 5.82901\n",
      "epoch 105 time 377.9424819946289 cost 5.77363\n",
      "epoch 106 time 381.15837001800537 cost 5.75853\n",
      "epoch 107 time 384.3772003650665 cost 5.52656\n",
      "epoch 108 time 387.52593183517456 cost 5.54622\n",
      "epoch 109 time 390.76696372032166 cost 5.5034\n",
      "epoch 110 time 393.99730229377747 cost 5.49532\n",
      "epoch 111 time 397.1692235469818 cost 5.24284\n",
      "epoch 112 time 400.3017475605011 cost 5.1831\n",
      "epoch 113 time 403.39420652389526 cost 5.16471\n",
      "epoch 114 time 406.6170015335083 cost 5.19046\n",
      "epoch 115 time 410.4048912525177 cost 4.83357\n",
      "epoch 116 time 414.32730770111084 cost 5.03177\n",
      "epoch 117 time 418.15463876724243 cost 5.01044\n",
      "epoch 118 time 422.474910736084 cost 4.93525\n",
      "epoch 119 time 426.8817889690399 cost 4.83777\n",
      "epoch 120 time 430.9719007015228 cost 4.74242\n",
      "epoch 121 time 434.7760851383209 cost 4.60696\n",
      "epoch 122 time 438.9288468360901 cost 4.426\n",
      "epoch 123 time 442.7026135921478 cost 4.4417\n",
      "epoch 124 time 446.95548820495605 cost 4.55442\n",
      "epoch 125 time 450.7973370552063 cost 4.32927\n",
      "epoch 126 time 454.9184582233429 cost 4.25928\n",
      "epoch 127 time 459.239670753479 cost 4.27717\n",
      "epoch 128 time 463.6272554397583 cost 4.23855\n",
      "epoch 129 time 467.5650985240936 cost 4.19991\n",
      "epoch 130 time 471.29877281188965 cost 4.0165\n",
      "epoch 131 time 474.9629228115082 cost 4.03756\n",
      "epoch 132 time 478.6915650367737 cost 4.09818\n",
      "epoch 133 time 482.6327872276306 cost 3.88345\n",
      "epoch 134 time 486.71600246429443 cost 3.80321\n",
      "epoch 135 time 490.87606978416443 cost 3.78408\n",
      "epoch 136 time 495.04748606681824 cost 3.83056\n",
      "epoch 137 time 499.53314685821533 cost 3.68351\n",
      "epoch 138 time 503.360228061676 cost 3.64389\n",
      "epoch 139 time 507.4394369125366 cost 3.56843\n",
      "epoch 140 time 511.61769342422485 cost 3.60836\n",
      "epoch 141 time 516.1220812797546 cost 3.50471\n",
      "epoch 142 time 520.0097777843475 cost 3.48635\n",
      "epoch 143 time 524.0310180187225 cost 3.42473\n",
      "epoch 144 time 528.1062514781952 cost 3.37307\n",
      "epoch 145 time 532.4107232093811 cost 3.27472\n",
      "epoch 146 time 536.7489402294159 cost 3.26613\n",
      "epoch 147 time 541.0210881233215 cost 3.25034\n",
      "epoch 148 time 545.158618927002 cost 3.18236\n",
      "epoch 149 time 549.4809799194336 cost 3.15201\n",
      "epoch 150 time 554.1398363113403 cost 3.20396\n",
      "epoch 151 time 558.1766846179962 cost 3.1159\n",
      "epoch 152 time 562.0595324039459 cost 3.14842\n",
      "epoch 153 time 566.2865288257599 cost 3.02085\n",
      "epoch 154 time 570.5235784053802 cost 2.90624\n",
      "epoch 155 time 574.8270401954651 cost 2.94574\n",
      "epoch 156 time 578.8690750598907 cost 2.87531\n",
      "epoch 157 time 583.2751243114471 cost 2.87989\n",
      "epoch 158 time 587.028039932251 cost 2.78411\n",
      "epoch 159 time 590.7494220733643 cost 2.74215\n",
      "epoch 160 time 594.0305299758911 cost 2.74685\n",
      "epoch 161 time 597.4755063056946 cost 2.74254\n",
      "epoch 162 time 601.1449370384216 cost 2.6212\n",
      "epoch 163 time 605.3457210063934 cost 2.6274\n",
      "epoch 164 time 609.8048112392426 cost 2.59346\n",
      "epoch 165 time 614.1714363098145 cost 2.62182\n",
      "epoch 166 time 618.6629726886749 cost 2.45262\n",
      "epoch 167 time 622.5842251777649 cost 2.46042\n",
      "epoch 168 time 626.9413733482361 cost 2.52438\n",
      "epoch 169 time 630.9452176094055 cost 2.45956\n",
      "epoch 170 time 635.234988451004 cost 2.40216\n",
      "epoch 171 time 639.4388988018036 cost 2.37661\n",
      "epoch 172 time 643.4904382228851 cost 2.34754\n",
      "epoch 173 time 647.2809484004974 cost 2.30422\n",
      "epoch 174 time 651.7375781536102 cost 2.29454\n",
      "epoch 175 time 655.9919631481171 cost 2.30452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176 time 660.6979994773865 cost 2.33836\n",
      "epoch 177 time 665.2198977470398 cost 2.21534\n",
      "epoch 178 time 669.1790518760681 cost 2.20743\n",
      "epoch 179 time 673.1483676433563 cost 2.21571\n",
      "epoch 180 time 676.9381420612335 cost 2.18916\n",
      "epoch 181 time 681.0135192871094 cost 2.05735\n",
      "epoch 182 time 685.3940849304199 cost 2.13116\n",
      "epoch 183 time 689.307867527008 cost 2.16634\n",
      "epoch 184 time 693.2925717830658 cost 2.05956\n",
      "epoch 185 time 697.5323371887207 cost 2.01453\n",
      "epoch 186 time 701.3504157066345 cost 1.97886\n",
      "epoch 187 time 705.4058990478516 cost 2.01828\n",
      "epoch 188 time 709.6099400520325 cost 1.98744\n",
      "epoch 189 time 712.910347700119 cost 1.91233\n",
      "epoch 190 time 716.687947511673 cost 1.9133\n",
      "epoch 191 time 720.3984217643738 cost 1.8875\n",
      "epoch 192 time 724.3519954681396 cost 1.87477\n",
      "epoch 193 time 727.9553666114807 cost 1.86611\n",
      "epoch 194 time 731.4852619171143 cost 1.85252\n",
      "epoch 195 time 735.1755728721619 cost 1.84128\n",
      "epoch 196 time 738.7915601730347 cost 1.77593\n",
      "epoch 197 time 742.2962183952332 cost 1.77909\n",
      "epoch 198 time 746.1903958320618 cost 1.75087\n",
      "epoch 199 time 750.1795139312744 cost 1.72053\n",
      "0.986250137648\n"
     ]
    }
   ],
   "source": [
    "score_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "500\n",
      "(5, 5, 1, 20)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "filter_shape=(5, 5, 1, 20)\n",
    "fan_in = np.prod(filter_shape[:3])\n",
    "fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "print(fan_in)\n",
    "print(fan_out)\n",
    "print(rng.uniform(low=-np.sqrt(6/(fan_in + fan_out)),high=np.sqrt(6/(fan_in + fan_out)),size=filter_shape).shape)\n",
    "b=np.zeros((filter_shape[3]), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
