{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. Tensorflowを用いて, MNISTを畳み込みニューラルネットワーク(CNN)で学習せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- homework関数を完成させて提出してください\n",
    "    - 訓練データはtrain_X, train_y, テストデータはtest_Xで与えられます\n",
    "    - train_Xとtrain_yをtrain_X, train_yとvalid_X, valid_yに分けるなどしてモデルを学習させてください\n",
    "    - test_Xに対して予想ラベルpred_yを作り, homework関数の戻り値としてください\\\n",
    "- pred_yのtest_yに対する精度(F値)で評価します\n",
    "- 全体の実行時間がiLect上で60分を超えないようにしてください\n",
    "- homework関数の外には何も書かないでください (必要なものは全てhomework関数に入れてください)\n",
    "- 解答提出時には Answer Cell の内容のみを提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf` の以下のモジュールはこの回では使用できないように制限されています. 注意してください.**\n",
    "```python\n",
    "tf.app\n",
    "tf.compat\n",
    "tf.contrib\n",
    "tf.erros\n",
    "tf.gfile\n",
    "tf.graph_util\n",
    "tf.image\n",
    "tf.layers\n",
    "tf.logging\n",
    "tf.losses\n",
    "tf.metrics\n",
    "tf.python_io\n",
    "tf.resource_loader\n",
    "tf.saved_model\n",
    "tf.sdca\n",
    "tf.sets\n",
    "tf.summary\n",
    "tf.sysconfig\n",
    "tf.test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルのhomework関数を完成させて提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt\n",
    "    #%matplotlib inline\n",
    "    rng = np.random.RandomState(1234)\n",
    "    random_state = 42\n",
    "    #Convolution layers [batchsize,picture_length,picture_width,color_channels]\n",
    "    class Conv:\n",
    "        def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
    "            # Xavier Initialization\n",
    "            fan_in = np.prod(filter_shape[:3])\n",
    "            fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "            self.W = tf.Variable(rng.uniform(\n",
    "                            low=-np.sqrt(6/(fan_in + fan_out)),\n",
    "                            high=np.sqrt(6/(fan_in + fan_out)),\n",
    "                            size=filter_shape\n",
    "                        ).astype('float32'), name='W')\n",
    "            self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
    "            self.function = function\n",
    "            self.strides = strides\n",
    "            self.padding = padding\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding)+self.b\n",
    "            return self.function(u)\n",
    "    class Conv_same:\n",
    "        def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='SAME'):\n",
    "            # Xavier Initialization\n",
    "            fan_in = np.prod(filter_shape[:3])\n",
    "            fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "            self.W = tf.Variable(rng.uniform(\n",
    "                            low=-np.sqrt(6/(fan_in + fan_out)),\n",
    "                            high=np.sqrt(6/(fan_in + fan_out)),\n",
    "                            size=filter_shape\n",
    "                        ).astype('float32'), name='W')\n",
    "            self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
    "            self.function = function\n",
    "            self.strides = strides\n",
    "            self.padding = padding\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding)+self.b\n",
    "            return self.function(u)\n",
    "    #Pooling layers [batchsize,picture_length,picture_width,color_channels]\n",
    "    class Pooling:\n",
    "        def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME'):\n",
    "            self.ksize = ksize\n",
    "            self.strides = strides\n",
    "            self.padding = padding\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
    "    #Flatten layer    \n",
    "    class Flatten:\n",
    "        def f_prop(self, x):\n",
    "            return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
    "    #Full-link layers\n",
    "    class Dense:\n",
    "        def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "            # Xavier Initialization\n",
    "            self.W = tf.Variable(rng.uniform(\n",
    "                            low=-np.sqrt(6/(in_dim + out_dim)),\n",
    "                            high=np.sqrt(6/(in_dim + out_dim)),\n",
    "                            size=(in_dim, out_dim)\n",
    "                        ).astype('float32'), name='W')\n",
    "            self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "            self.function = function\n",
    "\n",
    "        def f_prop(self, x):\n",
    "            return self.function(tf.matmul(x, self.W) + self.b)\n",
    "    \n",
    "    layers = [                            # (縦の次元数)x(横の次元数)x(チャネル数)\n",
    "        Conv_same((5, 5, 1, 20), tf.nn.relu),  # 28x28x 1 -> 28x28x20\n",
    "        Pooling((1, 2, 2, 1)),            # 28x28x20 -> 14x14x20\n",
    "        Conv((5, 5, 20, 50), tf.nn.relu), # 14x14x20 ->  10x 10x50\n",
    "        Pooling((1, 2, 2, 1)),            #  10x 10x50 ->  5x 5x50\n",
    "        Flatten(),\n",
    "        Dense(5*5*50, 10, tf.nn.softmax)\n",
    "    ]\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "    t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    def f_props(layers, x):\n",
    "        for layer in layers:\n",
    "            x = layer.f_prop(x)\n",
    "        return x\n",
    "\n",
    "    y = f_props(layers, x)\n",
    "\n",
    "    cost = -tf.reduce_mean(tf.reduce_sum(t * tf.log(tf.clip_by_value(y, 1e-10, 1.0)), axis=1)) # tf.log(0)によるnanを防ぐ\n",
    "    train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "    valid = tf.argmax(y, 1)\n",
    "    \n",
    "    n_epochs = 200\n",
    "    batch_size = 100\n",
    "    n_batches = train_X.shape[0]//batch_size\n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    cost_plt =[]\n",
    "    start_time=time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_X, train_y = shuffle(train_X, train_y, random_state=random_state)\n",
    "        cost_arry = []\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            _cost, _ = sess.run([cost,train], feed_dict={x: train_X[start:end], t: train_y[start:end]})\n",
    "            cost_arry.append(_cost)\n",
    "        cost_plt.append(np.sum(cost_arry))\n",
    "        tttttt = time.time()-start_time\n",
    "        print (\"epoch\",epoch,\"time\",tttttt,\"cost\",cost_plt[len(cost_plt)-1])\n",
    "\n",
    "        pred_y = sess.run(valid, feed_dict={x: test_X})\n",
    "        \n",
    "    sess.close()\n",
    "    plt.plot(np.log(cost_plt))\n",
    "    \n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以下のvalidate_homework関数を用いてエラーが起きないか動作確認をして下さい。\n",
    "- 提出に際して、以下のscore_homework関数で60分で実行が終わることを確認して下さい。\n",
    "- 評価は以下のscore_homework関数で行われますが、random_stateの値は変更されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "500\n",
      "(5, 5, 1, 20)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "filter_shape=(5, 5, 1, 20)\n",
    "fan_in = np.prod(filter_shape[:3])\n",
    "fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "print(fan_in)\n",
    "print(fan_out)\n",
    "print(rng.uniform(low=-np.sqrt(6/(fan_in + fan_out)),high=np.sqrt(6/(fan_in + fan_out)),size=filter_shape).shape)\n",
    "b=np.zeros((filter_shape[3]), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checker Cell (for student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "app",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c8f29b234267>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m del [\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: app"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "del [\n",
    "        tf.app,\n",
    "        tf.compat,\n",
    "        tf.contrib,\n",
    "        tf.errors,\n",
    "        tf.gfile,\n",
    "        tf.graph_util,\n",
    "        tf.image,\n",
    "        tf.layers,\n",
    "        tf.logging,\n",
    "        tf.losses,\n",
    "        tf.metrics,\n",
    "        tf.python_io,\n",
    "        tf.resource_loader,\n",
    "        tf.saved_model,\n",
    "        tf.sdca,\n",
    "        tf.sets,\n",
    "        tf.summary,\n",
    "        tf.sysconfig,\n",
    "        tf.test\n",
    "]\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "    mnist_X = np.r_[mnist.train.images, mnist.test.images]\n",
    "    mnist_y = np.r_[mnist.train.labels, mnist.test.labels]\n",
    "    return train_test_split(mnist_X, mnist_y, test_size=0.2, random_state=42)\n",
    "\n",
    "def validate_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    train_X = train_X.reshape((train_X.shape[0], 28, 28, 1))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 28, 28, 1))\n",
    "\n",
    "    # validate for small dataset\n",
    "    train_X_mini = train_X[:5000]\n",
    "    train_y_mini = train_y[:5000]\n",
    "    test_X_mini = test_X[:1000]\n",
    "    test_y_mini = test_y[:1000]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "    print(f1_score(np.argmax(test_y_mini, 1), pred_y, average='macro'))\n",
    "\n",
    "def score_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    train_X = train_X.reshape((train_X.shape[0], 28, 28, 1))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 28, 28, 1))\n",
    "    \n",
    "    pred_y = homework(train_X, train_y, test_X)\n",
    "    print(f1_score(np.argmax(test_y, 1), pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "epoch 0 time 0.4477651119232178 cost 112.248\n",
      "epoch 1 time 0.9165680408477783 cost 102.073\n",
      "epoch 2 time 1.2844080924987793 cost 76.6716\n",
      "epoch 3 time 1.7495510578155518 cost 44.8428\n",
      "epoch 4 time 2.2337489128112793 cost 30.2637\n",
      "epoch 5 time 2.7027482986450195 cost 24.2721\n",
      "epoch 6 time 3.1861469745635986 cost 20.8535\n",
      "epoch 7 time 3.5895297527313232 cost 18.7672\n",
      "epoch 8 time 3.8957719802856445 cost 17.2489\n",
      "epoch 9 time 4.18108057975769 cost 16.1913\n",
      "epoch 10 time 4.464359283447266 cost 15.0552\n",
      "epoch 11 time 4.749513864517212 cost 14.3718\n",
      "epoch 12 time 5.0282628536224365 cost 13.4638\n",
      "epoch 13 time 5.383425951004028 cost 12.8814\n",
      "epoch 14 time 5.751296758651733 cost 12.3032\n",
      "epoch 15 time 6.044710636138916 cost 11.8161\n",
      "epoch 16 time 6.405966758728027 cost 11.3092\n",
      "epoch 17 time 6.806913614273071 cost 10.9816\n",
      "epoch 18 time 7.238377332687378 cost 10.505\n",
      "epoch 19 time 7.620248317718506 cost 10.1276\n",
      "epoch 20 time 8.023961305618286 cost 9.71271\n",
      "epoch 21 time 8.408460140228271 cost 9.475\n",
      "epoch 22 time 8.755520582199097 cost 9.10285\n",
      "epoch 23 time 9.174073219299316 cost 8.89417\n",
      "epoch 24 time 9.476091623306274 cost 8.54868\n",
      "epoch 25 time 9.88176703453064 cost 8.30208\n",
      "epoch 26 time 10.269547700881958 cost 8.03663\n",
      "epoch 27 time 10.656779527664185 cost 7.82186\n",
      "epoch 28 time 11.110522747039795 cost 7.62218\n",
      "epoch 29 time 11.495462656021118 cost 7.38205\n",
      "epoch 30 time 11.911668300628662 cost 7.2662\n",
      "epoch 31 time 12.296538591384888 cost 6.79485\n",
      "epoch 32 time 12.675312757492065 cost 6.72407\n",
      "epoch 33 time 13.045170783996582 cost 6.4479\n",
      "epoch 34 time 13.329804182052612 cost 6.32782\n",
      "epoch 35 time 13.830596923828125 cost 6.22307\n",
      "epoch 36 time 14.346808671951294 cost 6.05512\n",
      "epoch 37 time 14.70067548751831 cost 5.84199\n",
      "epoch 38 time 15.04842233657837 cost 5.83737\n",
      "epoch 39 time 15.448060274124146 cost 5.62214\n",
      "epoch 40 time 15.783426761627197 cost 5.56043\n",
      "epoch 41 time 16.253548622131348 cost 5.27588\n",
      "epoch 42 time 16.650066375732422 cost 5.24743\n",
      "epoch 43 time 16.96646738052368 cost 5.07169\n",
      "epoch 44 time 17.34852623939514 cost 4.98103\n",
      "epoch 45 time 17.634708881378174 cost 4.94518\n",
      "epoch 46 time 17.917896509170532 cost 4.85989\n",
      "epoch 47 time 18.205389976501465 cost 4.63938\n",
      "epoch 48 time 18.49578857421875 cost 4.58265\n",
      "epoch 49 time 18.78464436531067 cost 4.52792\n",
      "epoch 50 time 19.103187799453735 cost 4.43105\n",
      "epoch 51 time 19.46915340423584 cost 4.28486\n",
      "epoch 52 time 19.83878493309021 cost 4.27843\n",
      "epoch 53 time 20.211451768875122 cost 4.06774\n",
      "epoch 54 time 20.499008655548096 cost 3.97187\n",
      "epoch 55 time 20.908291816711426 cost 3.98252\n",
      "epoch 56 time 21.355782508850098 cost 3.86618\n",
      "epoch 57 time 21.824161767959595 cost 3.79599\n",
      "epoch 58 time 22.275671243667603 cost 3.73372\n",
      "epoch 59 time 22.585699558258057 cost 3.61499\n",
      "epoch 60 time 22.87123966217041 cost 3.60821\n",
      "epoch 61 time 23.226001262664795 cost 3.58753\n",
      "epoch 62 time 23.588690996170044 cost 3.50981\n",
      "epoch 63 time 24.05879306793213 cost 3.44134\n",
      "epoch 64 time 24.4124596118927 cost 3.31609\n",
      "epoch 65 time 24.790666103363037 cost 3.27952\n",
      "epoch 66 time 25.190813779830933 cost 3.29725\n",
      "epoch 67 time 25.59186601638794 cost 3.17393\n",
      "epoch 68 time 25.94586968421936 cost 3.11338\n",
      "epoch 69 time 26.297566175460815 cost 3.03486\n",
      "epoch 70 time 26.73078727722168 cost 3.01291\n",
      "epoch 71 time 27.194135189056396 cost 2.92972\n",
      "epoch 72 time 27.61628818511963 cost 2.86428\n",
      "epoch 73 time 28.06405735015869 cost 2.86009\n",
      "epoch 74 time 28.58023977279663 cost 2.84095\n",
      "epoch 75 time 29.017032861709595 cost 2.78126\n",
      "epoch 76 time 29.514524698257446 cost 2.75632\n",
      "epoch 77 time 29.951332092285156 cost 2.65407\n",
      "epoch 78 time 30.31961679458618 cost 2.55312\n",
      "epoch 79 time 30.882946014404297 cost 2.51526\n",
      "epoch 80 time 31.33650231361389 cost 2.49533\n",
      "epoch 81 time 31.720582246780396 cost 2.49211\n",
      "epoch 82 time 32.092700481414795 cost 2.41212\n",
      "epoch 83 time 32.50015616416931 cost 2.43434\n",
      "epoch 84 time 32.899646520614624 cost 2.32738\n",
      "epoch 85 time 33.400996685028076 cost 2.33452\n",
      "epoch 86 time 33.739417552948 cost 2.28405\n",
      "epoch 87 time 34.12158441543579 cost 2.24483\n",
      "epoch 88 time 34.61894130706787 cost 2.17118\n",
      "epoch 89 time 34.932822465896606 cost 2.22382\n",
      "epoch 90 time 35.292542695999146 cost 2.16641\n",
      "epoch 91 time 35.68943738937378 cost 2.13078\n",
      "epoch 92 time 36.08876872062683 cost 2.0963\n",
      "epoch 93 time 36.54262733459473 cost 2.01244\n",
      "epoch 94 time 36.99072623252869 cost 2.00063\n",
      "epoch 95 time 37.45990967750549 cost 2.05526\n",
      "epoch 96 time 37.883585691452026 cost 1.98433\n",
      "epoch 97 time 38.15920925140381 cost 1.9786\n",
      "epoch 98 time 38.62811899185181 cost 1.92469\n",
      "epoch 99 time 39.09305024147034 cost 1.85623\n",
      "epoch 100 time 39.47755455970764 cost 1.85282\n",
      "epoch 101 time 39.93128800392151 cost 1.8451\n",
      "epoch 102 time 40.403995990753174 cost 1.78956\n",
      "epoch 103 time 40.718549966812134 cost 1.75821\n",
      "epoch 104 time 41.01680588722229 cost 1.71731\n",
      "epoch 105 time 41.37675666809082 cost 1.72551\n",
      "epoch 106 time 41.731435775756836 cost 1.66896\n",
      "epoch 107 time 42.050928354263306 cost 1.69245\n",
      "epoch 108 time 42.413779973983765 cost 1.58687\n",
      "epoch 109 time 42.752108573913574 cost 1.65398\n",
      "epoch 110 time 43.18113040924072 cost 1.56946\n",
      "epoch 111 time 43.52061915397644 cost 1.56536\n",
      "epoch 112 time 43.828040599823 cost 1.5331\n",
      "epoch 113 time 44.20571756362915 cost 1.52224\n",
      "epoch 114 time 44.616095781326294 cost 1.50017\n",
      "epoch 115 time 45.040390968322754 cost 1.47883\n",
      "epoch 116 time 45.58496022224426 cost 1.47694\n",
      "epoch 117 time 45.921125173568726 cost 1.41687\n",
      "epoch 118 time 46.285247802734375 cost 1.37913\n",
      "epoch 119 time 46.73344707489014 cost 1.33101\n",
      "epoch 120 time 47.019516706466675 cost 1.38826\n",
      "epoch 121 time 47.40295219421387 cost 1.34267\n",
      "epoch 122 time 47.74741768836975 cost 1.31556\n",
      "epoch 123 time 48.10287308692932 cost 1.30885\n",
      "epoch 124 time 48.51867365837097 cost 1.28356\n",
      "epoch 125 time 48.84713363647461 cost 1.26641\n",
      "epoch 126 time 49.13092303276062 cost 1.24877\n",
      "epoch 127 time 49.620723724365234 cost 1.23358\n",
      "epoch 128 time 50.05807447433472 cost 1.22247\n",
      "epoch 129 time 50.50548696517944 cost 1.23016\n",
      "epoch 130 time 50.97498106956482 cost 1.19082\n",
      "epoch 131 time 51.28003239631653 cost 1.16424\n",
      "epoch 132 time 51.56708025932312 cost 1.14233\n",
      "epoch 133 time 51.87640166282654 cost 1.10714\n",
      "epoch 134 time 52.24375081062317 cost 1.11669\n",
      "epoch 135 time 52.60833501815796 cost 1.08041\n",
      "epoch 136 time 53.008851289749146 cost 1.08058\n",
      "epoch 137 time 53.378475189208984 cost 1.05984\n",
      "epoch 138 time 53.800042152404785 cost 1.08838\n",
      "epoch 139 time 54.075045585632324 cost 1.07206\n",
      "epoch 140 time 54.4255313873291 cost 0.970945\n",
      "epoch 141 time 54.74762034416199 cost 1.02636\n",
      "epoch 142 time 55.36358618736267 cost 0.977682\n",
      "epoch 143 time 55.73862385749817 cost 0.983595\n",
      "epoch 144 time 56.2406370639801 cost 0.9894\n",
      "epoch 145 time 56.650259256362915 cost 1.00073\n",
      "epoch 146 time 57.09749722480774 cost 0.942665\n",
      "epoch 147 time 57.51001715660095 cost 0.944265\n",
      "epoch 148 time 57.93023228645325 cost 0.91033\n",
      "epoch 149 time 58.450334787368774 cost 0.922409\n",
      "epoch 150 time 58.949296712875366 cost 0.888949\n",
      "epoch 151 time 59.33238196372986 cost 0.860535\n",
      "epoch 152 time 59.83223247528076 cost 0.855379\n",
      "epoch 153 time 60.237884283065796 cost 0.844842\n",
      "epoch 154 time 60.617273807525635 cost 0.821429\n",
      "epoch 155 time 60.95539164543152 cost 0.867129\n",
      "epoch 156 time 61.31872868537903 cost 0.816905\n",
      "epoch 157 time 61.834470987319946 cost 0.770532\n",
      "epoch 158 time 62.33560848236084 cost 0.783512\n",
      "epoch 159 time 62.71964454650879 cost 0.796556\n",
      "epoch 160 time 63.0153591632843 cost 0.7493\n",
      "epoch 161 time 63.41959810256958 cost 0.753245\n",
      "epoch 162 time 63.75899815559387 cost 0.782452\n",
      "epoch 163 time 64.07498788833618 cost 0.742399\n",
      "epoch 164 time 64.425785779953 cost 0.714248\n",
      "epoch 165 time 64.8709146976471 cost 0.711461\n",
      "epoch 166 time 65.16044664382935 cost 0.702941\n",
      "epoch 167 time 65.53868341445923 cost 0.722768\n",
      "epoch 168 time 65.85601997375488 cost 0.71275\n",
      "epoch 169 time 66.17646431922913 cost 0.67257\n",
      "epoch 170 time 66.53950929641724 cost 0.680501\n",
      "epoch 171 time 66.86182713508606 cost 0.660707\n",
      "epoch 172 time 67.20899486541748 cost 0.661227\n",
      "epoch 173 time 67.54067873954773 cost 0.659152\n",
      "epoch 174 time 67.84097385406494 cost 0.64213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175 time 68.2701210975647 cost 0.618849\n",
      "epoch 176 time 68.57949233055115 cost 0.632125\n",
      "epoch 177 time 68.9954285621643 cost 0.617897\n",
      "epoch 178 time 69.39557361602783 cost 0.62319\n",
      "epoch 179 time 69.81857371330261 cost 0.623622\n",
      "epoch 180 time 70.14351844787598 cost 0.592882\n",
      "epoch 181 time 70.56296372413635 cost 0.585933\n",
      "epoch 182 time 71.04429006576538 cost 0.582841\n",
      "epoch 183 time 71.58266425132751 cost 0.559291\n",
      "epoch 184 time 71.96786999702454 cost 0.547082\n",
      "epoch 185 time 72.26842427253723 cost 0.572429\n",
      "epoch 186 time 72.61602091789246 cost 0.55382\n",
      "epoch 187 time 72.95046401023865 cost 0.549432\n",
      "epoch 188 time 73.3155300617218 cost 0.541283\n",
      "epoch 189 time 73.66708731651306 cost 0.527619\n",
      "epoch 190 time 74.00039482116699 cost 0.519624\n",
      "epoch 191 time 74.49205112457275 cost 0.526253\n",
      "epoch 192 time 74.9316794872284 cost 0.521971\n",
      "epoch 193 time 75.37416553497314 cost 0.508803\n",
      "epoch 194 time 75.81677746772766 cost 0.509743\n",
      "epoch 195 time 76.10203909873962 cost 0.49514\n",
      "epoch 196 time 76.40501999855042 cost 0.490898\n",
      "epoch 197 time 76.74958658218384 cost 0.509108\n",
      "epoch 198 time 77.06433534622192 cost 0.497004\n",
      "epoch 199 time 77.50342130661011 cost 0.481879\n",
      "0.96549517208\n"
     ]
    }
   ],
   "source": [
    "validate_homework()\n",
    "#score_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "epoch 0 time 4.268802881240845 cost 476.058\n",
      "epoch 1 time 8.225592613220215 cost 142.745\n",
      "epoch 2 time 12.664805173873901 cost 104.091\n",
      "epoch 3 time 16.280956745147705 cost 83.3433\n",
      "epoch 4 time 20.402664184570312 cost 70.0683\n",
      "epoch 5 time 24.54227304458618 cost 60.6506\n",
      "epoch 6 time 28.21463942527771 cost 54.093\n",
      "epoch 7 time 31.99765110015869 cost 49.0632\n",
      "epoch 8 time 36.18602919578552 cost 45.5722\n",
      "epoch 9 time 40.0205717086792 cost 42.0932\n",
      "epoch 10 time 43.9287805557251 cost 39.3256\n",
      "epoch 11 time 48.15277671813965 cost 37.0987\n",
      "epoch 12 time 52.55923390388489 cost 35.2567\n",
      "epoch 13 time 56.87964963912964 cost 33.2192\n",
      "epoch 14 time 60.900099992752075 cost 32.0834\n",
      "epoch 15 time 64.970778465271 cost 30.7415\n",
      "epoch 16 time 69.5376627445221 cost 29.3761\n",
      "epoch 17 time 73.72709798812866 cost 28.5522\n",
      "epoch 18 time 78.06202435493469 cost 27.5853\n",
      "epoch 19 time 82.42050337791443 cost 26.7429\n",
      "epoch 20 time 87.02586054801941 cost 25.7499\n",
      "epoch 21 time 91.37910103797913 cost 24.9902\n",
      "epoch 22 time 95.53573036193848 cost 24.2045\n",
      "epoch 23 time 99.1915671825409 cost 23.6605\n",
      "epoch 24 time 102.27302145957947 cost 22.8329\n",
      "epoch 25 time 105.54343962669373 cost 22.1449\n",
      "epoch 26 time 108.68710088729858 cost 21.7372\n",
      "epoch 27 time 112.33973503112793 cost 21.0631\n",
      "epoch 28 time 115.46572685241699 cost 20.656\n",
      "epoch 29 time 118.50168657302856 cost 20.2467\n",
      "epoch 30 time 122.15217399597168 cost 19.5051\n",
      "epoch 31 time 126.82424736022949 cost 19.1429\n",
      "epoch 32 time 130.5759983062744 cost 19.119\n",
      "epoch 33 time 133.4356300830841 cost 18.4373\n",
      "epoch 34 time 136.27697038650513 cost 17.9538\n",
      "epoch 35 time 139.15229845046997 cost 17.5802\n",
      "epoch 36 time 141.99800658226013 cost 17.3777\n",
      "epoch 37 time 145.169047832489 cost 17.0407\n",
      "epoch 38 time 149.3910903930664 cost 16.6399\n",
      "epoch 39 time 153.4664430618286 cost 16.3746\n",
      "epoch 40 time 156.45225405693054 cost 15.8606\n",
      "epoch 41 time 159.314608335495 cost 15.5166\n",
      "epoch 42 time 162.4275267124176 cost 15.4184\n",
      "epoch 43 time 166.50137639045715 cost 15.1356\n",
      "epoch 44 time 170.7231810092926 cost 14.7812\n",
      "epoch 45 time 175.01284885406494 cost 14.6417\n",
      "epoch 46 time 179.44974946975708 cost 14.3162\n",
      "epoch 47 time 183.20866227149963 cost 14.1094\n",
      "epoch 48 time 186.8124270439148 cost 13.8748\n",
      "epoch 49 time 190.31576442718506 cost 13.7453\n",
      "epoch 50 time 193.59069919586182 cost 13.2999\n",
      "epoch 51 time 196.98961424827576 cost 12.9724\n",
      "epoch 52 time 199.98521828651428 cost 12.7459\n",
      "epoch 53 time 202.95694851875305 cost 12.6145\n",
      "epoch 54 time 205.8745939731598 cost 12.6847\n",
      "epoch 55 time 208.7693314552307 cost 12.191\n",
      "epoch 56 time 211.67810368537903 cost 12.2249\n",
      "epoch 57 time 214.5980739593506 cost 11.7167\n",
      "epoch 58 time 217.4542784690857 cost 11.7789\n",
      "epoch 59 time 220.32266855239868 cost 11.4381\n",
      "epoch 60 time 223.1904628276825 cost 11.294\n",
      "epoch 61 time 226.04489254951477 cost 11.2584\n",
      "epoch 62 time 228.93148565292358 cost 10.9697\n",
      "epoch 63 time 231.79350447654724 cost 10.6366\n",
      "epoch 64 time 234.6759738922119 cost 10.5706\n",
      "epoch 65 time 237.59750294685364 cost 10.5434\n",
      "epoch 66 time 240.4991717338562 cost 10.1415\n",
      "epoch 67 time 243.3978555202484 cost 10.0637\n",
      "epoch 68 time 246.26115918159485 cost 10.0014\n",
      "epoch 69 time 249.131511926651 cost 9.88379\n",
      "epoch 70 time 252.0439100265503 cost 9.66159\n",
      "epoch 71 time 254.8979194164276 cost 9.43409\n",
      "epoch 72 time 257.7599949836731 cost 9.53452\n",
      "epoch 73 time 260.6268980503082 cost 9.30457\n",
      "epoch 74 time 263.4860415458679 cost 9.1448\n",
      "epoch 75 time 266.3486678600311 cost 9.10099\n",
      "epoch 76 time 269.27161169052124 cost 8.88749\n",
      "epoch 77 time 272.2333679199219 cost 8.7581\n",
      "epoch 78 time 275.9164640903473 cost 8.53297\n",
      "epoch 79 time 279.9436812400818 cost 8.4694\n",
      "epoch 80 time 284.151127576828 cost 8.35591\n",
      "epoch 81 time 288.17240023612976 cost 8.20071\n",
      "epoch 82 time 292.6631133556366 cost 8.0866\n",
      "epoch 83 time 297.0553488731384 cost 8.12058\n",
      "epoch 84 time 301.4897267818451 cost 7.82953\n",
      "epoch 85 time 304.9946279525757 cost 7.74188\n",
      "epoch 86 time 308.34671688079834 cost 7.62966\n",
      "epoch 87 time 312.66730785369873 cost 7.44003\n",
      "epoch 88 time 316.8565101623535 cost 7.37808\n",
      "epoch 89 time 321.0620450973511 cost 7.41297\n",
      "epoch 90 time 325.2026312351227 cost 7.13524\n",
      "epoch 91 time 329.3583092689514 cost 7.1174\n",
      "epoch 92 time 333.44513154029846 cost 6.94051\n",
      "epoch 93 time 337.26699328422546 cost 6.92575\n",
      "epoch 94 time 340.6869206428528 cost 6.78906\n",
      "epoch 95 time 344.3316674232483 cost 6.68365\n",
      "epoch 96 time 348.1782989501953 cost 6.64867\n",
      "epoch 97 time 351.7980227470398 cost 6.4805\n",
      "epoch 98 time 355.58804845809937 cost 6.33212\n",
      "epoch 99 time 358.6743507385254 cost 6.30216\n",
      "epoch 100 time 361.5457332134247 cost 6.34942\n",
      "epoch 101 time 364.5299139022827 cost 6.28847\n",
      "epoch 102 time 368.4402358531952 cost 6.02313\n",
      "epoch 103 time 372.53119802474976 cost 5.91492\n",
      "epoch 104 time 376.12663412094116 cost 5.82623\n",
      "epoch 105 time 379.5131106376648 cost 5.77087\n",
      "epoch 106 time 383.315735578537 cost 5.75931\n",
      "epoch 107 time 387.5382573604584 cost 5.52808\n",
      "epoch 108 time 391.96072125434875 cost 5.54609\n",
      "epoch 109 time 395.8750205039978 cost 5.50238\n",
      "epoch 110 time 399.01474237442017 cost 5.49699\n",
      "epoch 111 time 402.2876658439636 cost 5.24135\n",
      "epoch 112 time 405.830687046051 cost 5.18026\n",
      "epoch 113 time 409.191960811615 cost 5.16304\n",
      "epoch 114 time 412.58652663230896 cost 5.1883\n",
      "epoch 115 time 416.51079201698303 cost 4.83596\n",
      "epoch 116 time 419.84193110466003 cost 5.02901\n",
      "epoch 117 time 423.636426448822 cost 5.00587\n",
      "epoch 118 time 426.7681040763855 cost 4.93304\n",
      "epoch 119 time 429.7282645702362 cost 4.84102\n",
      "epoch 120 time 432.7661545276642 cost 4.73314\n",
      "epoch 121 time 435.9404835700989 cost 4.60996\n",
      "epoch 122 time 439.07574129104614 cost 4.42458\n",
      "epoch 123 time 442.20578789711 cost 4.43795\n",
      "epoch 124 time 445.4430820941925 cost 4.55844\n",
      "epoch 125 time 448.9591910839081 cost 4.3281\n",
      "epoch 126 time 452.4562449455261 cost 4.26021\n",
      "epoch 127 time 455.90316438674927 cost 4.27611\n",
      "epoch 128 time 459.3871839046478 cost 4.23588\n",
      "epoch 129 time 462.83560514450073 cost 4.19972\n",
      "epoch 130 time 466.2664785385132 cost 4.01525\n",
      "epoch 131 time 469.6998589038849 cost 4.03536\n",
      "epoch 132 time 473.13975739479065 cost 4.10305\n",
      "epoch 133 time 476.55558943748474 cost 3.88159\n",
      "epoch 134 time 480.00050115585327 cost 3.80241\n",
      "epoch 135 time 483.45042657852173 cost 3.78669\n",
      "epoch 136 time 486.8697683811188 cost 3.83298\n",
      "epoch 137 time 490.2916171550751 cost 3.68175\n",
      "epoch 138 time 493.719482421875 cost 3.64242\n",
      "epoch 139 time 497.1413311958313 cost 3.57014\n",
      "epoch 140 time 500.6268539428711 cost 3.60747\n",
      "epoch 141 time 504.13193011283875 cost 3.50921\n",
      "epoch 142 time 507.5958936214447 cost 3.48413\n",
      "epoch 143 time 511.0969593524933 cost 3.4265\n",
      "epoch 144 time 514.5699474811554 cost 3.37631\n",
      "epoch 145 time 518.0534653663635 cost 3.27621\n",
      "epoch 146 time 521.5434999465942 cost 3.26086\n",
      "epoch 147 time 525.095705986023 cost 3.25205\n",
      "epoch 148 time 528.6263513565063 cost 3.18445\n",
      "epoch 149 time 532.1775527000427 cost 3.14925\n",
      "epoch 150 time 535.6951630115509 cost 3.20745\n",
      "epoch 151 time 539.2388451099396 cost 3.1176\n",
      "epoch 152 time 542.7379069328308 cost 3.14775\n",
      "epoch 153 time 546.2369644641876 cost 3.02351\n",
      "epoch 154 time 549.7259969711304 cost 2.90596\n",
      "epoch 155 time 553.2265610694885 cost 2.9443\n",
      "epoch 156 time 556.7391571998596 cost 2.87452\n",
      "epoch 157 time 560.2412278652191 cost 2.88006\n",
      "epoch 158 time 563.7006797790527 cost 2.78531\n",
      "epoch 159 time 567.1882081031799 cost 2.74483\n",
      "epoch 160 time 570.6862647533417 cost 2.74714\n",
      "epoch 161 time 574.2219245433807 cost 2.73864\n",
      "epoch 162 time 577.7310121059418 cost 2.62186\n",
      "epoch 163 time 581.2506277561188 cost 2.62745\n",
      "epoch 164 time 584.7627234458923 cost 2.59403\n",
      "epoch 165 time 588.2602782249451 cost 2.62082\n",
      "epoch 166 time 591.758335351944 cost 2.45616\n",
      "epoch 167 time 595.2919895648956 cost 2.46161\n",
      "epoch 168 time 598.7965655326843 cost 2.5228\n",
      "epoch 169 time 602.306654214859 cost 2.4573\n",
      "epoch 170 time 605.828777551651 cost 2.40434\n",
      "epoch 171 time 609.3153023719788 cost 2.37957\n",
      "epoch 172 time 612.8399317264557 cost 2.34981\n",
      "epoch 173 time 616.3565394878387 cost 2.30481\n",
      "epoch 174 time 619.8761556148529 cost 2.29267\n",
      "epoch 175 time 623.3932650089264 cost 2.30113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176 time 626.9168951511383 cost 2.33705\n",
      "epoch 177 time 630.4615797996521 cost 2.21495\n",
      "epoch 178 time 633.9781873226166 cost 2.21027\n",
      "epoch 179 time 637.5183591842651 cost 2.21692\n",
      "epoch 180 time 641.0449950695038 cost 2.18887\n",
      "epoch 181 time 644.578147649765 cost 2.06209\n",
      "epoch 182 time 648.1052837371826 cost 2.13222\n",
      "epoch 183 time 651.6108617782593 cost 2.16396\n",
      "epoch 184 time 655.1861293315887 cost 2.05651\n",
      "epoch 185 time 658.7659091949463 cost 2.01144\n",
      "epoch 186 time 662.2614605426788 cost 1.97677\n",
      "epoch 187 time 665.785089969635 cost 2.01885\n",
      "epoch 188 time 669.3272686004639 cost 1.98801\n",
      "epoch 189 time 673.02436876297 cost 1.9141\n",
      "epoch 190 time 676.7580687999725 cost 1.9175\n",
      "epoch 191 time 680.4331092834473 cost 1.88799\n",
      "epoch 192 time 683.9236466884613 cost 1.87841\n",
      "epoch 193 time 687.4207007884979 cost 1.86805\n",
      "epoch 194 time 690.9408175945282 cost 1.85462\n",
      "epoch 195 time 694.4594311714172 cost 1.83836\n",
      "epoch 196 time 697.9770412445068 cost 1.77749\n",
      "epoch 197 time 701.5066845417023 cost 1.78333\n",
      "epoch 198 time 705.0884699821472 cost 1.75723\n",
      "epoch 199 time 708.6401736736298 cost 1.71909\n",
      "0.986331916929\n"
     ]
    }
   ],
   "source": [
    "score_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
