{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5回講義 演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. Tensorflowの基礎を学ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensorflowの概観"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`では, 基本的に以下の流れで機械学習モデルを構築します.\n",
    "\n",
    "1. プレースホルダーと変数の設定\n",
    "2. グラフの構築\n",
    "3. 誤差関数の設定\n",
    "4. 重みの更新ルールの設定\n",
    "5. `tf.Session()`を開始して学習\n",
    "6. 予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 線形回帰の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:: 10, cost:: 0.464\n",
      "iteration:: 20, cost:: 0.135\n",
      "iteration:: 30, cost:: 0.040\n",
      "iteration:: 40, cost:: 0.012\n",
      "iteration:: 50, cost:: 0.003\n",
      "iteration:: 60, cost:: 0.001\n",
      "iteration:: 70, cost:: 0.000\n",
      "iteration:: 80, cost:: 0.000\n",
      "iteration:: 90, cost:: 0.000\n",
      "iteration:: 100, cost:: 0.000\n",
      "pred_y: [ 13.00327778]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "# Step1. プレースホルダー・変数の設定\n",
    "## placeholder: データを流し込む変数. データ毎に変わる\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "\n",
    "## Variable: 変数(重み). データ間で共有される\n",
    "w = tf.Variable(0.0, name='w')\n",
    "b = tf.Variable(0.0, name='b')\n",
    "\n",
    "# Step2. グラフの構築\n",
    "y = w*x + b\n",
    "\n",
    "# Step3. 誤差関数の設定\n",
    "cost = tf.reduce_mean((y - t)**2)\n",
    "\n",
    "# Step4. 重みの更新則の設定\n",
    "gw, gb = tf.gradients(cost, [w, b]) # 勾配の計算\n",
    "updates = [\n",
    "    w.assign(w - 0.1*gw), # 勾配降下法\n",
    "    b.assign(b - 0.1*gb)\n",
    "]\n",
    "train = tf.group(*updates)\n",
    "\n",
    "# Step.5. 学習 (y = 2*x + 3)\n",
    "data_X = np.array([0., 1., 2., 3., 4.])\n",
    "data_y = np.array([3., 5., 7., 9., 11.])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 重みの初期化\n",
    "for i in range(100):\n",
    "    _cost, _ = sess.run([cost, train], feed_dict={x: data_X, t: data_y})\n",
    "    if (i+1)%10==0:\n",
    "        print('iteration:: %d, cost:: %.3f' % (i+1, _cost))\n",
    "\n",
    "# Step6. 予測\n",
    "print('pred_y:', sess.run(y, feed_dict={x: [5]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. プレースホルダー・変数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfには2種類の変数 (のようなもの) があります. それぞれ以下のように使い分けます."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.placeholder`: データ間で値が共有されない変数 (入力の`x`, 正解ラベルの `t` などに使用)\n",
    "- `tf.Variable` : データ間で値が共有される変数 (重みの `W`, `b` など更新されるものに使用）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.  `tf.placeholder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを流し込む入り口として使います.\n",
    "- 変数の型 (`tf.int32`, `tf.float32`) を指定する必要があります\n",
    "- 実行時にはデータを`feed_dict`で渡す必要があります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "y = x**2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict={x: 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. `tf.Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "値がデータ間で共有されるので, まず初期値を与える必要があります."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 全ての変数を初期化する場合は`tf.global_variables_initializer()`を使います.\n",
    "- 個別に変数を初期化する場合は`tf.variables_initializer()`を使い, 引数に初期化したい変数をリストで渡します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0.0, name='w')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(w.eval()) # print(sess.run(w))でも同じです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable_1\n\t [[Node: _send_Variable_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-4822618638951796669, tensor_name=\"Variable_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_1\n\t [[Node: _send_Variable_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-4822618638951796669, tensor_name=\"Variable_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a3b5671dc698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 初期化していないので, エラーが出ます.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \"\"\"\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minitialized_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \"\"\"\n\u001b[0;32m--> 569\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3739\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3740\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3741\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_1\n\t [[Node: _send_Variable_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-4822618638951796669, tensor_name=\"Variable_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1)]]"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0.0)\n",
    "b = tf.Variable(1.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([w]))\n",
    "    print(w.eval()) \n",
    "    print(b.eval()) # 初期化していないので, エラーが出ます."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIは`numpy`と非常に似ています. また, `numpy`と同じく要素毎に演算が行われます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7182817, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "exp_x = tf.exp(x)\n",
    "log_x = tf.log(x)\n",
    "sqrt_x = tf.sqrt(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([exp_x, log_x, sqrt_x], feed_dict={x: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ニューラルネットワーク用の関数は`tf.nn`以下にあります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7310586, 0.76159418, 1.0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "sigmoid_x = tf.nn.sigmoid(x)\n",
    "tanh_x = tf.nn.tanh(x)\n",
    "relu_x = tf.nn.relu(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([sigmoid_x, tanh_x, relu_x], feed_dict={x: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.mean, np.sum`等に対応するものは`tf.reduce_mean, tf.reduce_sum`等になります.\n",
    "- 引数`axis`で指定した軸に沿って演算を行います."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45.0, 4.5]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "sum_x = tf.reduce_sum(x, 0)\n",
    "mean_x = tf.reduce_mean(x, 0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([sum_x, mean_x], feed_dict={x: np.arange(10)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 行列・テンソル積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np` の `dot`, `matmul` に対応するものは `tf.matmul` ですが, 少し挙動が違うので注意する必要があります."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. 行列積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.matmul` を使用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.]\n",
      " [ 2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([2,2])\n",
    "b = tf.ones([2,2])\n",
    "\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ベクトルに対しても `tf.newaxis` などで明示的に行列に変換する必要があります."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.]\n",
      " [ 2.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([2,2])\n",
    "b = tf.ones(2)\n",
    "\n",
    "# c = tf.matmul(a, b) # エラー\n",
    "c = tf.matmul(a, b[:, tf.newaxis])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. テンソル積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```np```と同様に```tf```にも```einsum```があります. 3階以上のテンソルを含む計算はこれを用いるのがわかりやすくベターです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  6.  6.  6.]\n",
      "24.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([2,3,4])\n",
    "b = tf.ones([2,3])\n",
    "\n",
    "c = tf.einsum('ijk,ij->k', a, b)\n",
    "sum_c = tf.einsum('ijk,ij->', a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())\n",
    "    print(sum_c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. 条件・比較演算子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件演算子は\n",
    "- `tf.cond(condition, if true(関数), if false(関数))`\n",
    "です."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')\n",
    "\n",
    "absl = tf.cond(x > y, lambda: x - y, lambda: y - x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(absl, feed_dict={x: 100, y:  50}))\n",
    "    print(sess.run(absl, feed_dict={x:  50, y: 100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比較演算子は\n",
    "- `tf.equal`\n",
    "- `tf.greater` (>でも可)\n",
    "- `tf.less` (<でも可)\n",
    "\n",
    "などを使います."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')\n",
    "\n",
    "absl = tf.cond(tf.greater(x, y), lambda: x - y, lambda: y - x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(absl, feed_dict={x: 100, y:  50}))\n",
    "    print(sess.run(absl, feed_dict={x:  50, y: 100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他の言語のfor文に対応するものは`tf.scan`ですが, これはRNNの回で扱います."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 勾配 (微分) の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.gradients`をつかうことで微分を計算することができます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0]\n",
      "[4.0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = x**2\n",
    "\n",
    "grads = tf.gradients(y, x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x: 1.}))\n",
    "    print(sess.run(grads, feed_dict={x: 2.}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二引数(`xs`)に複数の変数を指定すると, それぞれに対する偏微分をリストで返します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 64.0]\n",
      "[18.0, 512.0]\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.placeholder(tf.float32, name='x1')\n",
    "x2 = tf.placeholder(tf.float32, name='x2')\n",
    "y = 3*x1**2 + 2*x2**4\n",
    "\n",
    "grads = tf.gradients(y, [x1, x2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x1: 1, x2: 2}))\n",
    "    print(sess.run(grads, feed_dict={x1: 3, x2: 4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 変数 (Variable) の更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assign, assign_add, assign_sub` メソッドにより行います."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0, name='w')\n",
    "\n",
    "add_one = a.assign_add(1.)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        print(sess.run(add_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数の更新をまとめる場合は `tf.group` を使用します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1.0,  b: 9.0\n",
      "a: 2.0,  b: 8.0\n",
      "a: 3.0,  b: 7.0\n",
      "a: 4.0,  b: 6.0\n",
      "a: 5.0,  b: 5.0\n",
      "a: 6.0,  b: 4.0\n",
      "a: 7.0,  b: 3.0\n",
      "a: 8.0,  b: 2.0\n",
      "a: 9.0,  b: 1.0\n",
      "a: 10.0,  b: 0.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0, name='w')\n",
    "b = tf.Variable(10.0, name='b')\n",
    "\n",
    "add_one = a.assign_add(1.)\n",
    "sub_one = b.assign_sub(1.)\n",
    "\n",
    "updates = [\n",
    "    add_one,\n",
    "    sub_one\n",
    "]\n",
    "\n",
    "train = tf.group(*updates)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(train)\n",
    "        print('a:', a.eval(), end=',  ')\n",
    "        print('b:', b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. TensorBoardによるグラフの表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowで計算グラフの構築方法を扱ってきましたが, ここでは構築した計算グラフの可視化をし, 視覚的に捉えてみましょう.\n",
    "\n",
    "計算グラフを表示するには, tensorboard.py [\\[引用元\\]](http://qiita.com/kegamin/items/887c7dfe8bbb76197741) を読み込む必要があります.\n",
    "\n",
    "tensorboard.pyをimportしたら, `show_graph`関数にグラフを渡すことで可視化できます.\n",
    "\n",
    "可視化結果はインタラクティブな表示になるので, 拡大や移動, 詳細表示等を試してみましょう."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorboard' has no attribute 'show_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b46f171d0e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 単純な足し算のグラフの表示 (がしたいが...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorboard' has no attribute 'show_graph'"
     ]
    }
   ],
   "source": [
    "import tensorboard as tb\n",
    "\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([c], feed_dict={a:2, b:3}))\n",
    "\n",
    "tb.show_graph(sess.graph)    # 単純な足し算のグラフの表示 (がしたいが...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. グラフの管理と整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1. デフォルトグラフ\n",
    "\n",
    "グラフが表示されたものの, 大変ごちゃごちゃしており, 足し算以外のグラフも表示されてしまったかと思います.\n",
    "\n",
    "これは, 今回の演習でこれまでに実行された計算グラフがすべて表示されてしまっているためです.\n",
    "\n",
    "TensorFlowでは何も指定しなければ, デフォルトグラフと呼ばれるグラフ上に計算グラフを構築します.\n",
    "\n",
    "一度計算グラフ上に配置されたグラフは, そのグラフを使うか使わないかにかかわらず, 全てリセットされることなく蓄積されていきます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 't' type=Placeholder>,\n",
       " <tf.Operation 'w/initial_value' type=Const>,\n",
       " <tf.Operation 'w' type=VariableV2>,\n",
       " <tf.Operation 'w/Assign' type=Assign>,\n",
       " <tf.Operation 'w/read' type=Identity>,\n",
       " <tf.Operation 'b/initial_value' type=Const>,\n",
       " <tf.Operation 'b' type=VariableV2>,\n",
       " <tf.Operation 'b/Assign' type=Assign>,\n",
       " <tf.Operation 'b/read' type=Identity>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Rank' type=Rank>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'Mean' type=Mean>,\n",
       " <tf.Operation 'gradients/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Const' type=Const>,\n",
       " <tf.Operation 'gradients/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Size' type=Size>,\n",
       " <tf.Operation 'gradients/Mean_grad/add' type=Add>,\n",
       " <tf.Operation 'gradients/Mean_grad/mod' type=FloorMod>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/Mean_grad/range/start' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/range/delta' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/range' type=Range>,\n",
       " <tf.Operation 'gradients/Mean_grad/Fill/value' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients/Mean_grad/DynamicStitch' type=DynamicStitch>,\n",
       " <tf.Operation 'gradients/Mean_grad/Maximum/y' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Maximum' type=Maximum>,\n",
       " <tf.Operation 'gradients/Mean_grad/floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'gradients/Mean_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape_2' type=Shape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape_3' type=Shape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Const' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Prod' type=Prod>,\n",
       " <tf.Operation 'gradients/Mean_grad/Const_1' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Prod_1' type=Prod>,\n",
       " <tf.Operation 'gradients/Mean_grad/Maximum_1/y' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Maximum_1' type=Maximum>,\n",
       " <tf.Operation 'gradients/Mean_grad/floordiv_1' type=FloorDiv>,\n",
       " <tf.Operation 'gradients/Mean_grad/Cast' type=Cast>,\n",
       " <tf.Operation 'gradients/Mean_grad/truediv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/pow_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/pow_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/pow_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/pow_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/pow_grad/sub/y' type=Const>,\n",
       " <tf.Operation 'gradients/pow_grad/sub' type=Sub>,\n",
       " <tf.Operation 'gradients/pow_grad/Pow' type=Pow>,\n",
       " <tf.Operation 'gradients/pow_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/pow_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/pow_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/pow_grad/Greater/y' type=Const>,\n",
       " <tf.Operation 'gradients/pow_grad/Greater' type=Greater>,\n",
       " <tf.Operation 'gradients/pow_grad/Log' type=Log>,\n",
       " <tf.Operation 'gradients/pow_grad/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients/pow_grad/Select' type=Select>,\n",
       " <tf.Operation 'gradients/pow_grad/mul_2' type=Mul>,\n",
       " <tf.Operation 'gradients/pow_grad/mul_3' type=Mul>,\n",
       " <tf.Operation 'gradients/pow_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/pow_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/sub_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/sub_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/sub_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/sub_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/sub_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/sub_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/sub_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/sub_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/add_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/add_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/add_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/add_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/add_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/add_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/mul_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/mul_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/mul_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/mul_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/mul_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/mul_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/mul_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/mul_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'mul_1/x' type=Const>,\n",
       " <tf.Operation 'mul_1' type=Mul>,\n",
       " <tf.Operation 'sub_1' type=Sub>,\n",
       " <tf.Operation 'Assign' type=Assign>,\n",
       " <tf.Operation 'mul_2/x' type=Const>,\n",
       " <tf.Operation 'mul_2' type=Mul>,\n",
       " <tf.Operation 'sub_2' type=Sub>,\n",
       " <tf.Operation 'Assign_1' type=Assign>,\n",
       " <tf.Operation 'group_deps' type=NoOp>,\n",
       " <tf.Operation 'init' type=NoOp>,\n",
       " <tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'pow_1/y' type=Const>,\n",
       " <tf.Operation 'pow_1' type=Pow>,\n",
       " <tf.Operation 'w_1/initial_value' type=Const>,\n",
       " <tf.Operation 'w_1' type=VariableV2>,\n",
       " <tf.Operation 'w_1/Assign' type=Assign>,\n",
       " <tf.Operation 'w_1/read' type=Identity>,\n",
       " <tf.Operation 'init_1' type=NoOp>,\n",
       " <tf.Operation 'Variable/initial_value' type=Const>,\n",
       " <tf.Operation 'Variable' type=VariableV2>,\n",
       " <tf.Operation 'Variable/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable/read' type=Identity>,\n",
       " <tf.Operation 'Variable_1/initial_value' type=Const>,\n",
       " <tf.Operation 'Variable_1' type=VariableV2>,\n",
       " <tf.Operation 'Variable_1/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable_1/read' type=Identity>,\n",
       " <tf.Operation 'init_2' type=NoOp>,\n",
       " <tf.Operation 'Placeholder_1' type=Placeholder>,\n",
       " <tf.Operation 'Exp' type=Exp>,\n",
       " <tf.Operation 'Log' type=Log>,\n",
       " <tf.Operation 'Sqrt' type=Sqrt>,\n",
       " <tf.Operation 'Placeholder_2' type=Placeholder>,\n",
       " <tf.Operation 'Sigmoid' type=Sigmoid>,\n",
       " <tf.Operation 'Tanh' type=Tanh>,\n",
       " <tf.Operation 'Relu' type=Relu>,\n",
       " <tf.Operation 'Placeholder_3' type=Placeholder>,\n",
       " <tf.Operation 'Sum/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Sum' type=Sum>,\n",
       " <tf.Operation 'Mean_1/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_1' type=Mean>,\n",
       " <tf.Operation 'ones' type=Const>,\n",
       " <tf.Operation 'ones_1' type=Const>,\n",
       " <tf.Operation 'MatMul' type=MatMul>,\n",
       " <tf.Operation 'ones_2' type=Const>,\n",
       " <tf.Operation 'ones_3' type=Const>,\n",
       " <tf.Operation 'strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'ones_4' type=Const>,\n",
       " <tf.Operation 'ones_5' type=Const>,\n",
       " <tf.Operation 'transpose/perm' type=Const>,\n",
       " <tf.Operation 'transpose' type=Transpose>,\n",
       " <tf.Operation 'transpose_1/perm' type=Const>,\n",
       " <tf.Operation 'transpose_1' type=Transpose>,\n",
       " <tf.Operation 'Reshape/shape' type=Const>,\n",
       " <tf.Operation 'Reshape' type=Reshape>,\n",
       " <tf.Operation 'Reshape_1/shape' type=Const>,\n",
       " <tf.Operation 'Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'MatMul_2' type=MatMul>,\n",
       " <tf.Operation 'Reshape_2/shape' type=Const>,\n",
       " <tf.Operation 'Reshape_2' type=Reshape>,\n",
       " <tf.Operation 'transpose_2/perm' type=Const>,\n",
       " <tf.Operation 'transpose_2' type=Transpose>,\n",
       " <tf.Operation 'transpose_3/perm' type=Const>,\n",
       " <tf.Operation 'transpose_3' type=Transpose>,\n",
       " <tf.Operation 'transpose_4/perm' type=Const>,\n",
       " <tf.Operation 'transpose_4' type=Transpose>,\n",
       " <tf.Operation 'Reshape_3/shape' type=Const>,\n",
       " <tf.Operation 'Reshape_3' type=Reshape>,\n",
       " <tf.Operation 'Reshape_4/shape' type=Const>,\n",
       " <tf.Operation 'Reshape_4' type=Reshape>,\n",
       " <tf.Operation 'MatMul_3' type=MatMul>,\n",
       " <tf.Operation 'Reshape_5/shape' type=Const>,\n",
       " <tf.Operation 'Reshape_5' type=Reshape>,\n",
       " <tf.Operation 'Sum_1/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Sum_1' type=Sum>,\n",
       " <tf.Operation 'transpose_5/perm' type=Const>,\n",
       " <tf.Operation 'transpose_5' type=Transpose>,\n",
       " <tf.Operation 'x_1' type=Placeholder>,\n",
       " <tf.Operation 'y' type=Placeholder>,\n",
       " <tf.Operation 'Greater' type=Greater>,\n",
       " <tf.Operation 'cond/Switch' type=Switch>,\n",
       " <tf.Operation 'cond/switch_t' type=Identity>,\n",
       " <tf.Operation 'cond/switch_f' type=Identity>,\n",
       " <tf.Operation 'cond/pred_id' type=Identity>,\n",
       " <tf.Operation 'cond/sub/Switch' type=Switch>,\n",
       " <tf.Operation 'cond/sub/Switch_1' type=Switch>,\n",
       " <tf.Operation 'cond/sub' type=Sub>,\n",
       " <tf.Operation 'cond/sub_1/Switch' type=Switch>,\n",
       " <tf.Operation 'cond/sub_1/Switch_1' type=Switch>,\n",
       " <tf.Operation 'cond/sub_1' type=Sub>,\n",
       " <tf.Operation 'cond/Merge' type=Merge>,\n",
       " <tf.Operation 'x_2' type=Placeholder>,\n",
       " <tf.Operation 'y_1' type=Placeholder>,\n",
       " <tf.Operation 'Greater_1' type=Greater>,\n",
       " <tf.Operation 'cond_1/Switch' type=Switch>,\n",
       " <tf.Operation 'cond_1/switch_t' type=Identity>,\n",
       " <tf.Operation 'cond_1/switch_f' type=Identity>,\n",
       " <tf.Operation 'cond_1/pred_id' type=Identity>,\n",
       " <tf.Operation 'cond_1/sub/Switch' type=Switch>,\n",
       " <tf.Operation 'cond_1/sub/Switch_1' type=Switch>,\n",
       " <tf.Operation 'cond_1/sub' type=Sub>,\n",
       " <tf.Operation 'cond_1/sub_1/Switch' type=Switch>,\n",
       " <tf.Operation 'cond_1/sub_1/Switch_1' type=Switch>,\n",
       " <tf.Operation 'cond_1/sub_1' type=Sub>,\n",
       " <tf.Operation 'cond_1/Merge' type=Merge>,\n",
       " <tf.Operation 'x_3' type=Placeholder>,\n",
       " <tf.Operation 'pow_2/y' type=Const>,\n",
       " <tf.Operation 'pow_2' type=Pow>,\n",
       " <tf.Operation 'gradients_1/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients_1/Const' type=Const>,\n",
       " <tf.Operation 'gradients_1/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/sub/y' type=Const>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/sub' type=Sub>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Pow' type=Pow>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Greater/y' type=Const>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Greater' type=Greater>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Log' type=Log>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Select' type=Select>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/mul_2' type=Mul>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/mul_3' type=Mul>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients_1/pow_2_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'x1' type=Placeholder>,\n",
       " <tf.Operation 'x2' type=Placeholder>,\n",
       " <tf.Operation 'pow_3/y' type=Const>,\n",
       " <tf.Operation 'pow_3' type=Pow>,\n",
       " <tf.Operation 'mul_3/x' type=Const>,\n",
       " <tf.Operation 'mul_3' type=Mul>,\n",
       " <tf.Operation 'pow_4/y' type=Const>,\n",
       " <tf.Operation 'pow_4' type=Pow>,\n",
       " <tf.Operation 'mul_4/x' type=Const>,\n",
       " <tf.Operation 'mul_4' type=Mul>,\n",
       " <tf.Operation 'add_1' type=Add>,\n",
       " <tf.Operation 'gradients_2/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients_2/Const' type=Const>,\n",
       " <tf.Operation 'gradients_2/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients_2/add_1_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients_2/add_1_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients_2/add_1_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients_2/add_1_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients_2/add_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/add_1_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients_2/add_1_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients_2/mul_3_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients_2/mul_4_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/sub/y' type=Const>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/sub' type=Sub>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Pow' type=Pow>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Greater/y' type=Const>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Greater' type=Greater>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Log' type=Log>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Select' type=Select>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/mul_2' type=Mul>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/mul_3' type=Mul>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients_2/pow_3_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/sub/y' type=Const>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/sub' type=Sub>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Pow' type=Pow>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Greater/y' type=Const>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Greater' type=Greater>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Log' type=Log>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Select' type=Select>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/mul_2' type=Mul>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/mul_3' type=Mul>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients_2/pow_4_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'w_2/initial_value' type=Const>,\n",
       " <tf.Operation 'w_2' type=VariableV2>,\n",
       " <tf.Operation 'w_2/Assign' type=Assign>,\n",
       " <tf.Operation 'w_2/read' type=Identity>,\n",
       " <tf.Operation 'AssignAdd/value' type=Const>,\n",
       " <tf.Operation 'AssignAdd' type=AssignAdd>,\n",
       " <tf.Operation 'init_3' type=NoOp>,\n",
       " <tf.Operation 'w_3/initial_value' type=Const>,\n",
       " <tf.Operation 'w_3' type=VariableV2>,\n",
       " <tf.Operation 'w_3/Assign' type=Assign>,\n",
       " <tf.Operation 'w_3/read' type=Identity>,\n",
       " <tf.Operation 'b_1/initial_value' type=Const>,\n",
       " <tf.Operation 'b_1' type=VariableV2>,\n",
       " <tf.Operation 'b_1/Assign' type=Assign>,\n",
       " <tf.Operation 'b_1/read' type=Identity>,\n",
       " <tf.Operation 'AssignAdd_1/value' type=Const>,\n",
       " <tf.Operation 'AssignAdd_1' type=AssignAdd>,\n",
       " <tf.Operation 'AssignSub/value' type=Const>,\n",
       " <tf.Operation 'AssignSub' type=AssignSub>,\n",
       " <tf.Operation 'group_deps_1' type=NoOp>,\n",
       " <tf.Operation 'init_4' type=NoOp>,\n",
       " <tf.Operation 'Placeholder_4' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_5' type=Placeholder>,\n",
       " <tf.Operation 'add_2' type=Add>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今までの実行によりデフォルトグラフ上に溜まったオペレーション\n",
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'b:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'w_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'w_2:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'w_3:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'b_1:0' shape=() dtype=float32_ref>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables() # Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.  `tf.reset_default_graph`関数によるリセット\n",
    "\n",
    "このままでは, 使わないゴミリソースが蓄積してしまう上, TensorBoardで可視化する際にも無関係のグラフまで表示され見づらくなってしまいます.\n",
    "\n",
    "特にJupyter等のインタラクティブな環境では全体で1セッションなので, こうした傾向が顕著であり, 途中でリセット処理を書くことが重要です.\n",
    "\n",
    "対処法としては, 毎回新しくグラフを構築する際に `tf.reset_default_graph()` によりグラフをリセットすることです.\n",
    "\n",
    "こうすることで毎回クリーンな状態でグラフを構築していくことができます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "print(tf.get_default_graph().get_operations())\n",
    "print(tf.global_variables())\n",
    "\n",
    "# 再び足し算のグラフを構築・表示\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c, feed_dict={a:2, b:3}))\n",
    "\n",
    "print(tf.get_default_graph().get_operations())\n",
    "print(tf.global_variables())\n",
    "tb.show_graph(tf.Session().graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3. 複雑なグラフの整理\n",
    "\n",
    "グラフを表示したとき, 各ノードの名前は基本的に自動で割り振られます.\n",
    "\n",
    "ただ, これでは少し規模が大きくなるだけですぐにコードとの対応をつけるのが難しくなります.\n",
    "\n",
    "そこで, 定数・変数やプレースホルダーなどには `name`引数を明示的に指定し, ノード名を与えておきましょう."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 線形回帰の例\n",
    "\n",
    "# グラフのリセット\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# プレースホルダーと変数の宣言\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "W = tf.Variable(tf.random_uniform([5,3], -1.0, 1.0), name='W')\n",
    "b = tf.Variable(tf.zeros([3]), name='b')\n",
    "\n",
    "# グラフの構築\n",
    "y = tf.add(tf.matmul(x, W), b, name='y')\n",
    "\n",
    "# 誤差関数の定義\n",
    "loss = tf.reduce_mean((y - t)**2, name='loss')\n",
    "\n",
    "tb.show_graph(tf.Session().graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "かなりコードと対応がつき, 見やすくなりました.\n",
    "\n",
    "しかし, 今後より大規模なグラフを扱う際には, 今のままでは頂点が余りにも多くなってしまい, 見ずらくなってしまいます.\n",
    "\n",
    "そこで頂点をまとめることを考えると, これには tf.name_scope 関数を用います.\n",
    "\n",
    "まとめられた頂点は, カーソルをかざすと出てくる右上のプラスマークをクリックすることで展開することができます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# グラフのリセット\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "\n",
    "with tf.name_scope('variables'):\n",
    "    W = tf.Variable(tf.random_uniform([5,3], -1.0, 1.0), name='W')\n",
    "    b = tf.Variable(tf.zeros([3]), name='b')\n",
    "\n",
    "with tf.name_scope('model'):\n",
    "    y = tf.add(tf.matmul(x, W), b, name='y')\n",
    "\n",
    "with tf.name_scope('training'):\n",
    "    loss = tf.reduce_mean(tf.square(y - t), name='loss')\n",
    "\n",
    "tb.show_graph(tf.Session().graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4. グラフの切り分け\n",
    "\n",
    "デフォルトグラフではなく, 明示的にグラフオブジェクトを作成し, その上にグラフを構築していくことでグラフ環境を他と分けることもできます.\n",
    "\n",
    "これは複数のグラフを構築していきたいときなどに便利です."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "g0 = tf.get_default_graph() # デフォルトグラフオブジェクトを取得することも可能\n",
    "\n",
    "g1 = tf.Graph() # グラフオブジェクトの作成1\n",
    "\n",
    "a = tf.constant(2, name='a0') # これはdefault graphへの配置になるので注意\n",
    "b = a**a\n",
    "\n",
    "with g1.as_default(): # デフォルトに設定した上で, グラフを構築・操作\n",
    "    a = tf.constant(2, name='a')\n",
    "    b = a**a\n",
    "\n",
    "g2 = tf.Graph() # グラフオブジェクトの作成2\n",
    "\n",
    "with g2.as_default(): # デフォルトに設定し, グラフを構築\n",
    "    a = tf.constant(4, name='a')\n",
    "    x = tf.constant(3, name='x')\n",
    "    y = a**x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb.show_graph(g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g1) as sess:\n",
    "    print(sess.run(b))\n",
    "tb.show_graph(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g2) as sess:\n",
    "    print(sess.run(y))\n",
    "tb.show_graph(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※注意\n",
    "\n",
    "ここで紹介している方法は, グラフの表示のみに対応しています.\n",
    "\n",
    "TensorBoardそのものはグラフ以外にも, 学習中のパラメータの変化など様々な可視化に対応しているのですが,\n",
    "\n",
    "Jupyter上では対応が進んでおらず, TensorBoardをフルに活用できないのです.\n",
    "\n",
    "Jupyterを用いずに手元の環境で行う場合, およそ次の方法でフルのTensorBoardを使用できます. (tensorboard.pyは不要です)\n",
    "\n",
    "1. tf.Session 中で tf.summary.FileWriter 関数によりログの出力を設定\n",
    "\n",
    "2. ターミナルで \"tensorboard --logdir= (ログの出力先) \" を実行\n",
    "\n",
    "3. localhost:6006にブラウザからアクセス\n",
    "\n",
    "より興味が湧いた方はぜひ手元の環境で下の公式情報を参考に他の可視化についても試してください.\n",
    "\n",
    "参考:\n",
    "- https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "- https://www.tensorflow.org/get_started/embedding_viz\n",
    "- https://www.tensorflow.org/get_started/graph_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 自動微分を使ったロジスティック回帰の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットに OR を用いてロジスティック回帰を実装してみましょう. パラメータの勾配の計算には `tf` の自動微分機能 `tf.gradients` を使ってみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 予測確率の計算\n",
    "$$\n",
    "    y = \\sigma({\\bf W}^{\\mathrm{T}}{\\bf x} + {\\bf b})\n",
    "$$\n",
    "- 誤差関数: 交差エントロピー\n",
    "$$\n",
    "    E = -\\sum^N_{i=1} [t_i \\log y_i + (1 - t_i) \\log (1 - y_i) ]\n",
    "$$\n",
    "- 勾配降下法によるパラメータの更新 ($\\epsilon$: 学習率)\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf W}^{(l)} &\\leftarrow {\\bf W}^{(l)} - \\epsilon \\frac{\\partial E}{\\partial {\\bf W}^{(l)}}  \\\\\n",
    "    {\\bf b}^{(l)} &\\leftarrow {\\bf b}^{(l)} - \\epsilon \\frac{\\partial E}{\\partial {\\bf b}^{(l)}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "# Step1. プレースホルダーと変数の定義\n",
    "## プレースホルダー\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "\n",
    "## 変数\n",
    "W = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(2, 1)).astype('float32'), name='W')\n",
    "b = tf.Variable(np.zeros(1).astype('float32'), name='b')\n",
    "\n",
    "# Step2. グラフの構築\n",
    "y = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "# Step3. 誤差関数の定義\n",
    "# cost = -tf.reduce_mean(t*tf.log(y) + (1 - t)*tf.log(1 - y))\n",
    "cost = -tf.reduce_mean(t*tf.log(tf.clip_by_value(y, 1e-10, 1.0)) + (1 - t)*tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0))) # tf.log(0)によるnanを防ぐ\n",
    "\n",
    "# Step4. 更新則の設定\n",
    "gW, gb = tf.gradients(cost, [W, b])\n",
    "updates = [\n",
    "    W.assign_add(-0.01*gW),\n",
    "    b.assign_add(-0.01*gb)\n",
    "]\n",
    "train = tf.group(*updates)\n",
    "\n",
    "# OR\n",
    "train_X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
    "train_y = np.array([[1], [1], [0], [1]])\n",
    "\n",
    "# Step5. 学習\n",
    "with tf.Session() as sess:\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        _cost, _ = sess.run([cost, train], feed_dict={x: train_X, t: train_y})\n",
    "        if (i+1)%1000==0:\n",
    "            print(_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 自動微分を使った多層パーセプトロン (Multilayer perceptron, MLP) の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットに MNIST を用いて MLP を実装してみましょう. パラメータの勾配の計算には `tf` の自動微分機能 `tf.gradients` を使ってみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 順伝播\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf u}^{(1)} &= {\\bf W}^{(1)\\mathrm{T}} {\\bf x} + {\\bf b}^{(1)} \\\\\n",
    "    {\\bf z}^{(1)} &= \\sigma({\\bf u}^{(1)}) \\\\\n",
    "    {\\bf u}^{(2)} &= {\\bf W}^{(2)\\mathrm{T}} {\\bf z^{(1)}} + {\\bf b}^{(2)} \\\\\n",
    "    {\\bf y} &= \\mathrm{softmax} ({\\bf u}^{(2)})\n",
    "\\end{align*}\n",
    "$$\n",
    "- 誤差関数: 多クラス交差エントロピー\n",
    "$$\n",
    "    E = -\\sum^N_{i=1} \\sum^K_{k=1} t_{ik} \\log y_{ik}\n",
    "$$\n",
    "- 勾配降下法によるパラメータの更新 ($\\epsilon$: 学習率)\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf W}^{(l)} &\\leftarrow {\\bf W}^{(l)} - \\epsilon \\frac{\\partial E}{\\partial {\\bf W}^{(l)}}  \\\\\n",
    "    {\\bf b}^{(l)} &\\leftarrow {\\bf b}^{(l)} - \\epsilon \\frac{\\partial E}{\\partial {\\bf b}^{(l)}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "EPOCH:: 1, Validation cost: 1444.336, Validation F1: 0.918\n",
      "EPOCH:: 2, Validation cost: 1163.071, Validation F1: 0.935\n",
      "EPOCH:: 3, Validation cost: 940.541, Validation F1: 0.948\n",
      "EPOCH:: 4, Validation cost: 797.488, Validation F1: 0.957\n",
      "EPOCH:: 5, Validation cost: 736.668, Validation F1: 0.959\n",
      "EPOCH:: 6, Validation cost: 682.948, Validation F1: 0.962\n",
      "EPOCH:: 7, Validation cost: 623.634, Validation F1: 0.966\n",
      "EPOCH:: 8, Validation cost: 589.146, Validation F1: 0.966\n",
      "EPOCH:: 9, Validation cost: 563.881, Validation F1: 0.968\n",
      "EPOCH:: 10, Validation cost: 555.381, Validation F1: 0.969\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "# Step1. プレースホルダーと変数の定義\n",
    "## Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "## 変数\n",
    "W1 = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(784, 200)).astype('float32'), name='W1')\n",
    "b1 = tf.Variable(np.zeros(200).astype('float32'), name='b1')\n",
    "W2 = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(200, 10)).astype('float32'), name='W2')\n",
    "b2 = tf.Variable(np.zeros(10).astype('float32'), name='b2')\n",
    "params = [W1, b1, W2, b2]\n",
    "\n",
    "# Step2. グラフの定義\n",
    "u1 = tf.matmul(x, W1) + b1\n",
    "z1 = tf.nn.sigmoid(u1)\n",
    "u2 = tf.matmul(z1, W2) + b2\n",
    "y = tf.nn.softmax(u2)\n",
    "\n",
    "# Step3. 誤差関数の定義\n",
    "# cost = -tf.reduce_mean(tf.reduce_sum(t*tf.log(y)))\n",
    "cost = -tf.reduce_mean(tf.reduce_sum(t*tf.log(tf.clip_by_value(y, 1e-10, 1.0)))) # tf.log(0)によるnanを防ぐ\n",
    "\n",
    "# Step4. 更新則の設定\n",
    "gW1, gb1, gW2, gb2 = tf.gradients(cost, params)\n",
    "updates = [\n",
    "    W1.assign_add(-0.01*gW1),\n",
    "    b1.assign_add(-0.01*gb1),\n",
    "    W2.assign_add(-0.01*gW2),\n",
    "    b2.assign_add(-0.01*gb2)\n",
    "]\n",
    "\n",
    "train = tf.group(*updates)\n",
    "\n",
    "valid = tf.argmax(y, 1)\n",
    "\n",
    "# MNIST\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "mnist_X, mnist_y = mnist.train.images, mnist.train.labels\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(mnist_X, mnist_y, test_size=0.1, random_state=random_state)\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = train_X.shape[0] // batch_size\n",
    "\n",
    "# Step5. 学習\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        train_X, train_y = shuffle(train_X, train_y, random_state=random_state)\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            sess.run(train, feed_dict={x: train_X[start:end], t: train_y[start:end]})\n",
    "        pred_y, valid_cost = sess.run([valid, cost], feed_dict={x: valid_X, t: valid_y})\n",
    "        print('EPOCH:: %i, Validation cost: %.3f, Validation F1: %.3f' % (epoch + 1, valid_cost, f1_score(np.argmax(valid_y, 1).astype('int32'), pred_y, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 参考資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Tensorflow Documentation](https://www.tensorflow.org/api_docs/)\n",
    "2. [Tensorflow Tutorial](https://www.tensorflow.org/tutorials/mandelbrot)\n",
    "2. [CS 20SI: Tensorflow for Deep Leaning Research](http://web.stanford.edu/class/cs20si/)\n",
    "3. [CS224d: Tensorflow Tutorial](https://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
